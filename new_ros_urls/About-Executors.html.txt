concepts intermediate concepts executors edit on github executors ï overview ï execution management in ros 2 is handled by executors. an executor uses one or more threads of the underlying operating system to invoke the callbacks of s, timers, service servers, action servers, etc. on incoming messages and events. the explicit executor class (in executor.hpp in rclcpp, in executors.py in rclpy, or in executor.h in rclc) provides more control over execution management than the spin mechanism in ros 1, although the basic api is very similar. in the following, we focus on the c++ client library rclcpp . basic use ï in the simplest case, the main thread is used for processing the incoming messages and events of a node by calling rclcpp::spin(..) as follows: int main ( int argc , char * argv []) { // some initialization. rclcpp :: init ( argc , argv ); ... // instantiate a node. rclcpp :: node :: sharedptr node = ... // run the executor. rclcpp :: spin ( node ); // shutdown and exit. ... return 0 ; } the call to spin(node) basically expands to an instantiation and invocation of the single-threaded executor, which is the simplest executor: rclcpp :: executors :: singlethreadedexecutor executor ; executor . add_node ( node ); executor . spin (); by invoking spin() of the executor instance, the current thread starts querying the rcl and middleware layers for incoming messages and other events and calls the corresponding callback functions until the node shuts down. in order not to counteract the qos settings of the middleware, an incoming message is not stored in a queue on the client library layer but kept in the middleware until it is taken for processing by a callback function. (this is a crucial difference to ros 1.) a wait set is used to inform the executor  available messages on the middleware layer, with one binary flag per queue. the wait set is also used to detect when timers expire. the single-threaded executor is also used by the container process for components , i.e. in all cases where nodes are created and executed without an explicit main function. types of executors ï currently, rclcpp provides three executor types, derived from a shared parent class: the multi-threaded executor creates a configurable number of threads to allow for processing multiple messages or events in parallel. the static single-threaded executor optimizes the runtime costs for scanning the structure of a node in  of s, timers, service servers, action servers, etc. it performs this scan only once when the node is added, while the other two executors regularly scan for such changes. therefore, the static single-threaded executor should be used only with nodes that create all s, timers, etc. during initialization. all three executors can be used with multiple nodes by calling add_node(..) for each node. rclcpp :: node :: sharedptr node1 = ... rclcpp :: node :: sharedptr node2 = ... rclcpp :: node :: sharedptr node3 = ... rclcpp :: executors :: staticsinglethreadedexecutor executor ; executor . add_node ( node1 ); executor . add_node ( node2 ); executor . add_node ( node3 ); executor . spin (); in the above example, the one thread of a static single-threaded executor is used to serve three nodes together. in case of a multi-threaded executor, the actual parallelism depends on the callback groups. callback groups ï ros 2 allows organizing the callbacks of a node in groups. in rclcpp, such a callback group can be created by the create_callback_group function of the node class. in rclpy, the same is done by calling the constructor of the specific callback group type. the callback group must be stored throughout execution of the node (eg. as a class member), or otherwise the executor wonât be able to trigger the callbacks. then, this callback group can be specified when creating a , timer, etc. - for example by the  options: c++ python my_callback_group = create_callback_group ( rclcpp :: callbackgrouptype :: mutuallyexclusive ); rclcpp :: options options ; options . callback_group = my_callback_group ; my_ = create_ < int32 > ( "/topic" , rclcpp :: sensordataqos (), callback , options ); my_callback_group = mutuallyexclusivecallbackgroup () my_ = self . create_ ( int32 , "/topic" , self . callback , qos_profile = 1 , callback_group = my_callback_group ) all s, timers, etc. that are created without the indication of a callback group are assigned to the default callback group . the default callback group can be queried via nodebaseinterface::get_default_callback_group() in rclcpp and by node.default_callback_group in rclpy. there are two types of callback groups, where the type has to be specified at instantiation time: mutually exclusive: callbacks of this group must not be executed in parallel. reentrant: callbacks of this group may be executed in parallel. callbacks of different callback groups may always be executed in parallel. the multi-threaded executor uses its threads as a pool to process as many callbacks as possible in parallel according to these conditions. for tips on how to use callback groups efficiently, see using callback groups . the executor base class in rclcpp also has the function add_callback_group(..) , which allows distributing callback groups to different executors. by configuring the underlying threads using the operating system scheduler, specific callbacks can be prioritized over other callbacks. for example, the s and timers of a control loop can be prioritized over all other s and standard services of a node. the examples_rclcpp_cbg_executor package provides a demo of this mechanism. scheduling semantics ï if the processing time of the callbacks is shorter than the period with which messages and events occur, the executor basically processes them in fifo order. however, if the processing time of some callbacks is longer, messages and events will be queued on the lower layers of the stack. the wait set mechanism reports only very little information  these queues to the executor. in detail, it only reports whether there are any messages for a certain topic or not. the executor uses this information to process the messages (including services and actions) in a round-robin fashion - but not in fifo order. the following flow diagram visualizes this scheduling semantics. this semantics was first described in a paper by casini et al. at ecrts 2019 . (note: the paper also explains that timer events are prioritized over all other messages. this prioritization was removed in eloquent. ) outlook ï while the three executors of rclcpp work well for most applications, there are some issues that make them not suitable for real-time applications, which require well-defined execution times, determinism, and custom control over the execution order. here is a summary of some of these issues: complex and mixed scheduling semantics. ideally you want well defined scheduling semantics to perform a formal timing analysis. callbacks may suffer from priority inversion. higher priority callbacks may be blocked by lower priority callbacks. no explicit control over the callbacks execution order. no built-in control over triggering for specific topics. additionally, the executor overhead in  of cpu and memory usage is considerable. the static single-threaded executor reduces this overhead greatly but it might not be enough for some applications. these issues have been partially addressed by the following developments: rclcpp waitset : the waitset class of rclcpp allows waiting directly on s, timers, service servers, action servers, etc. instead of using an executor. it can be used to implement deterministic, user-defined processing sequences, possibly processing multiple messages from different s together. the examples_rclcpp_wait_set package provides several examples for the use of this user-level wait set mechanism. rclc executor : this executor from the c client library rclc , developed for micro-ros, gives the user fine-grained control over the execution order of callbacks and allows for custom trigger conditions to activate callbacks. furthermore, it implements ideas of the logical execution time (let) semantics. further information ï michael pãhnl et al.: âros 2 executor: how to make it efficient, real-time and deterministic?â . workshop at ros world 2021. virtual event. 19 october 2021. ralph lange: âadvanced execution management with ros 2â . ros industrial conference. virtual event. 16 december 2020. daniel casini, tobias blass, ingo lã¼tkebohle, and bjãrn brandenburg: âresponse-time analysis of rosâ 2 processing chains under reservation-based schedulingâ , proc. of 31st ecrts 2019, stuttgart, germany, july 2019. other versions v: jazzy releases jazzy (latest) iron humble galactic (eol) foxy (eol) eloquent (eol) dashing (eol) crystal (eol) in development rolling