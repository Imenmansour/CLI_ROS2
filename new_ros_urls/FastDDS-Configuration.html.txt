tutorials advanced unlocking the potential of fast dds middleware [community-contributed] edit on github unlocking the potential of fast dds middleware [community-contributed] ï goal: this tutorial will show how to use the extended configuration capabilities of fast dds in ros 2. tutorial level: advanced time: 20 minutes background ï the interface between the ros 2 stack and fast dds is provided by the ros 2 middleware implementation rmw_fastrtps . this implementation is available in all ros 2 distributions, both from binaries and from sources. ros 2 rmw only allows for the configuration of certain middleware qos (see ros 2 qos policies ). however, rmw_fastrtps offers extended configuration capabilities to take full advantage of the features in fast dds . this tutorial will guide you through a series of examples explaining how to use xml files to unlock this extended configuration. in order to get more information  using fast dds on ros 2,  check the following documentation . prerequisites ï this tutorial assumes that you know how to create a package . it also assumes you know how to write a simple publisher and subscriber and a simple service and client . although the examples are implemented in c++, the same concepts apply to python packages. mixing synchronous and asynchronous publications in the same node ï in this first example, a node with two publishers, one of them with synchronous publication mode and the other one with asynchronous publication mode, will be created. rmw_fastrtps uses synchronous publication mode by default. with synchronous publication mode the data is sent directly within the context of the user thread. this entails that any blocking call occurring during the write operation would block the user thread, thus preventing the application from continuing its operation. however, this mode typically yields higher throughput rates at lower latencies, since there is no notification nor context switching between threads. on the other hand, with asynchronous publication mode, each time the publisher invokes the write operation, the data is copied into a queue, a background thread (asynchronous thread) is notified  the addition to the queue, and control of the thread is returned to the user before the data is actually sent. the background thread is in charge of consuming the queue and sending the data to every matched reader. create the node with the publishers ï first, create a new package named sync_async_node_example_cpp on a new workspace: linux macos windows mkdir -p ~/ros2_ws/src cd ~/ros2_ws/src ros2 pkg create --build-type ament_cmake --license apache-2.0 --dependencies rclcpp std_msgs -- sync_async_node_example_cpp mkdir -p ~/ros2_ws/src cd ~/ros2_ws/src ros2 pkg create --build-type ament_cmake --license apache-2.0 --dependencies rclcpp std_msgs -- sync_async_node_example_cpp md \ros2_ws\src cd \ros2_ws\src ros2 pkg create --build-type ament_cmake --license apache-2.0 --dependencies rclcpp std_msgs -- sync_async_node_example_cpp then, add a file named src/sync_async_writer.cpp to the package, with the following content. note that the synchronous publisher will be publishing on topic sync_topic , while the asynchronous one will be publishing on topic async_topic . #include <chrono> #include <functional> #include <memory> #include <string> #include "rclcpp/rclcpp.hpp" #include "std_msgs/msg/string.hpp" using namespace std :: chrono_literals ; class syncasyncpublisher : public rclcpp :: node { public : syncasyncpublisher () : node ( "sync_async_publisher" ), count_ ( 0 ) { // create the synchronous publisher on topic 'sync_topic' sync_publisher_ = this -> create_publisher < std_msgs :: msg :: string > ( "sync_topic" , 10 ); // create the asynchronous publisher on topic 'async_topic' async_publisher_ = this -> create_publisher < std_msgs :: msg :: string > ( "async_topic" , 10 ); // actions to run every time the timer expires auto timer_callback = [ this ](){ // create a new message to be sent auto sync_message = std_msgs :: msg :: string (); sync_message . data = "sync: hello, world! " + std :: to_string ( count_ ); // log the message to the console to show progress rclcpp_info ( this -> get_logger (), "synchronously publishing: '%s'" , sync_message . data . c_str ()); // publish the message using the synchronous publisher sync_publisher_ -> publish ( sync_message ); // create a new message to be sent auto async_message = std_msgs :: msg :: string (); async_message . data = "async: hello, world! " + std :: to_string ( count_ ); // log the message to the console to show progress rclcpp_info ( this -> get_logger (), "asynchronously publishing: '%s'" , async_message . data . c_str ()); // publish the message using the asynchronous publisher async_publisher_ -> publish ( async_message ); // prepare the count for the next message count_ ++ ; }; // this timer will trigger the publication of new data every half a second timer_ = this -> create_wall_timer ( 500 ms , timer_callback ); } private : // this timer will trigger the publication of new data every half a second rclcpp :: timerbase :: sharedptr timer_ ; // a publisher that publishes asynchronously rclcpp :: publisher < std_msgs :: msg :: string >:: sharedptr async_publisher_ ; // a publisher that publishes synchronously rclcpp :: publisher < std_msgs :: msg :: string >:: sharedptr sync_publisher_ ; // number of messages sent so far size_t count_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < syncasyncpublisher > ()); rclcpp :: shutdown (); return 0 ; } now open the cmakelists.txt file and add a new executable and name it syncasyncwriter so you can run your node using ros2 run : add_executable ( syncasyncwriter src/sync_async_writer.cpp ) ament_target_dependencies ( syncasyncwriter rclcpp std_msgs ) finally, add the install(targetsâ) section so ros2 run can find your executable: install ( targets syncasyncwriter destination lib/ { project_name } ) you can clean up your cmakelists.txt by removing some unnecessary sections and comments, so it looks like this: cmake_minimum_required ( version 3.8 ) project ( sync_async_node_example_cpp ) # default to c++14 if ( not cmake_cxx_standard ) set ( cmake_cxx_standard 14 ) endif () if ( cmake_compiler_is_gnucxx or cmake_cxx_compiler_id matches "clang" ) add_compile_options ( -wall -wextra -wpedantic ) endif () find_package ( ament_cmake required ) find_package ( rclcpp required ) find_package ( std_msgs required ) add_executable ( syncasyncwriter src/sync_async_writer.cpp ) ament_target_dependencies ( syncasyncwriter rclcpp std_msgs ) install ( targets syncasyncwriter destination lib/ { project_name } ) ament_package () if this node is built and run now, both publishers will behave the same, publishing asynchronously in both topics, because this is the default publication mode. the default publication mode configuration can be changed in runtime during the node launching, using an xml file. create the xml file with the profile configuration ï create a file with name syncasync.xml and the following content: <?xml version="1.0" encoding="utf-8" ?> <profiles xmlns= "http://www.eprosima.com/xmlschemas/fastrtps_profiles" > <!-- default publisher profile --> <publisher profile_name= "default_publisher" is_default_profile= "true" > <historymemorypolicy> dynamic </historymemorypolicy> </publisher> <!-- default subscriber profile --> <subscriber profile_name= "default_subscriber" is_default_profile= "true" > <historymemorypolicy> dynamic </historymemorypolicy> </subscriber> <!-- publisher profile for topic sync_topic --> <publisher profile_name= "/sync_topic" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> synchronous </kind> </publishmode> </qos> </publisher> <!-- publisher profile for topic async_topic --> <publisher profile_name= "/async_topic" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> asynchronous </kind> </publishmode> </qos> </publisher> </profiles> note that several profiles for publisher and subscriber are defined. two default profiles which are defined setting the is_default_profile to true , and two profiles with names that coincide with those of the previously defined topics: sync_topic and another one for async_topic . these last two profiles set the publication mode to synchronous or asynchronous accordingly. note also that all profiles specify a historymemorypolicy value, which is needed for the example to work, and the reason will be explained later on this tutorial. execute the publisher node ï you will need to export the following environment variables for the xml to be loaded: linux macos windows export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/syncasync.xml export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/syncasync.xml set rmw_implementation=rmw_fastrtps_cpp set rmw_fastrtps_use_qos_from_xml=1 set fastrtps_default_profiles_file=path/to/syncasync.xml finally, ensure you have sourced your setup files and run the node: source install/setup.bash ros2 run sync_async_node_example_cpp syncasyncwriter you should see the publishers sending the data from the publishing node, like so: [info] [1612972049.994630332] [sync_async_publisher]: synchronously publishing: 'sync: hello, world! 0' [info] [1612972049.995097767] [sync_async_publisher]: asynchronously publishing: 'async: hello, world! 0' [info] [1612972050.494478706] [sync_async_publisher]: synchronously publishing: 'sync: hello, world! 1' [info] [1612972050.494664334] [sync_async_publisher]: asynchronously publishing: 'async: hello, world! 1' [info] [1612972050.994368474] [sync_async_publisher]: synchronously publishing: 'sync: hello, world! 2' [info] [1612972050.994549851] [sync_async_publisher]: asynchronously publishing: 'async: hello, world! 2' now you have a synchronous publisher and an asynchronous publisher running inside the same node. create a node with the subscribers ï next, a new node with the subscribers that will listen to the sync_topic and async_topic publications is going to be created. in a new source file named src/sync_async_reader.cpp write the following content: #include <memory> #include "rclcpp/rclcpp.hpp" #include "std_msgs/msg/string.hpp" class syncasyncsubscriber : public rclcpp :: node { public : syncasyncsubscriber () : node ( "sync_async_subscriber" ) { // lambda function to run every time a new message is received auto topic_callback = [ this ]( const std_msgs :: msg :: string & msg ){ rclcpp_info ( this -> get_logger (), "i heard: '%s'" , msg . data . c_str ()); }; // create the synchronous subscriber on topic 'sync_topic' // and tie it to the topic_callback sync__ = this -> create_ < std_msgs :: msg :: string > ( "sync_topic" , 10 , topic_callback ); // create the asynchronous subscriber on topic 'async_topic' // and tie it to the topic_callback async__ = this -> create_ < std_msgs :: msg :: string > ( "async_topic" , 10 , topic_callback ); } private : // a subscriber that listens to topic 'sync_topic' rclcpp ::  < std_msgs :: msg :: string >:: sharedptr sync__ ; // a subscriber that listens to topic 'async_topic' rclcpp ::  < std_msgs :: msg :: string >:: sharedptr async__ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < syncasyncsubscriber > ()); rclcpp :: shutdown (); return 0 ; } open the cmakelists.txt file and add a new executable and name it syncasyncreader under the previous syncasyncwriter : add_executable ( syncasyncreader src/sync_async_reader.cpp ) ament_target_dependencies ( syncasyncreader rclcpp std_msgs ) install ( targets syncasyncreader destination lib/ { project_name } ) execute the subscriber node ï with the publisher node running in one terminal, open another one and export the required environment variables for the xml to be loaded: linux macos windows export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/syncasync.xml export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/syncasync.xml set rmw_implementation=rmw_fastrtps_cpp set rmw_fastrtps_use_qos_from_xml=1 set fastrtps_default_profiles_file=path/to/syncasync.xml finally, ensure you have sourced your setup files and run the node: source install/setup.bash ros2 run sync_async_node_example_cpp syncasyncreader you should see the subscribers receiving the data from the publishing node, like so: [info] [1612972054.495429090] [sync_async_subscriber]: i heard: 'sync: hello, world! 10' [info] [1612972054.995410057] [sync_async_subscriber]: i heard: 'async: hello, world! 10' [info] [1612972055.495453494] [sync_async_subscriber]: i heard: 'sync: hello, world! 11' [info] [1612972055.995396561] [sync_async_subscriber]: i heard: 'async: hello, world! 11' [info] [1612972056.495534818] [sync_async_subscriber]: i heard: 'sync: hello, world! 12' [info] [1612972056.995473953] [sync_async_subscriber]: i heard: 'async: hello, world! 12' analysis of the example ï configuration profiles xml ï the xml file defines several configurations for publishers and subscribers. you can have a default publisher configuration profile and several topic-specific publisher profiles. the only requirement is that all publisher profiles have a different name and that there is only a single default profile. the same goes for subscribers. in order to define a configuration for a specific topic, just name the profile after the the ros 2 topic name (like /sync_topic and /async_topic in the example), and rmw_fastrtps will apply this profile to all publishers and subscribers for that topic. the default configuration profile is identified by the attribute is_default_profile set to true , and acts as a fallback profile when there is no other one with a name matching the topic name. the environment variable fastrtps_default_profiles_file is used to inform fast dds the path to the xml file with the configuration profiles to load. rmw_fastrtps_use_qos_from_xml ï among all the configurable attributes, rmw_fastrtps treats publishmode and historymemorypolicy differently. by default, these values are set to asynchronous and preallocated_with_realloc within the rmw_fastrtps implementation, and the values set on the xml file are ignored. in order to use the values in the xml file, the environment variable rmw_fastrtps_use_qos_from_xml must be set to 1 . however, this entails another caveat : if rmw_fastrtps_use_qos_from_xml is set, but the xml file does not define publishmode or historymemorypolicy , these attributes take the fast dds default value instead of the rmw_fastrtps default value. this is important, especially for historymemorypolicy , because the fast dds deafult value is preallocated which does not work with ros2 topic data types. therefore, in the example, a valid value for this policy has been explicitly set ( dynamic ). prioritization of rmw_qos_profile_t ï ros 2 qos contained in rmw_qos_profile_t are always honored, unless set to *_system_default . in that case, xml values (or fast dds default values in the absence of xml ones) are applied. this means that if any qos in rmw_qos_profile_t is set to something other than *_system_default , the corresponding value in the xml is ignored. using other fastdds capabilities with xml ï although we have created a node with two publishers with different configuration, it is not easy to check that they are behaving differently. now that the basics of xml profiles have been covered, let us use them to configure something which has some visual effect on the nodes. specifically, a maximum number of matching subscribers on one of the publishers and a partition definition on the other will be set. note that these are only very simple examples among all the configuration attributes that can be tuned on rmw_fastrtps through xml files.  refer to *fast dds* documentation to see the whole list of attributes that can be configured through xml files. limiting the number of matching subscribers ï add a maximum number of matched subscribers to the /async_topic publisher profile. it should look like this: <!-- publisher profile for topic async_topic --> <publisher profile_name= "/async_topic" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> asynchronous </kind> </publishmode> </qos> <matchedsubscribersallocation> <initial> 0 </initial> <maximum> 1 </maximum> <increment> 1 </increment> </matchedsubscribersallocation> </publisher> the number of matching subscribers is being limited to one. now open three terminals and do not forget to source the setup files and to set the required environment variables. on the first terminal run the publisher node, and the subscriber node on the other two. you should see that only the first subscriber node receives the messages from both topics. the second one could not complete the matching process in the /async_topic because the publisher prevented it, as it had already reached its maximum of matched publishers. consequently, only the messages from the /sync_topic are going to be received in this third terminal: [info] [1613127657.088860890] [sync_async_subscriber]: i heard: 'sync: hello, world! 18' [info] [1613127657.588896594] [sync_async_subscriber]: i heard: 'sync: hello, world! 19' [info] [1613127658.088849401] [sync_async_subscriber]: i heard: 'sync: hello, world! 20' using partitions within the topic ï the partitions feature can be used to control which publishers and subscribers exchange information within the same topic. partitions introduce a logical entity isolation level concept inside the physical isolation induced by a domain id. for a publisher to communicate with a subscriber, they have to belong at least to one common partition. partitions represent another level to separate publishers and subscribers beyond domain and topic. unlike domain and topic, an endpoint can belong to several partitions at the same time. for certain data to be shared over different domains or topics, there must be a different publisher for each, sharing its own history of changes. however, a single publisher can share the same data sample over different partitions using a single topic data change, thus reducing network overload. let us change the /sync_topic publisher to partition part1 and create a new /sync_topic subscriber which uses partition part2 . their profiles should now look like this: <!-- publisher profile for topic sync_topic --> <publisher profile_name= "/sync_topic" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> synchronous </kind> </publishmode> <partition> <names> <name> part1 </name> </names> </partition> </qos> </publisher> <!-- subscriber profile for topic sync_topic --> <subscriber profile_name= "/sync_topic" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <partition> <names> <name> part2 </name> </names> </partition> </qos> </subscriber> open two terminals. do not forget to source the setup files and to set the required environment variables. on the first terminal run the publisher node, and the subscriber node on the other one. you should see that only the /async_topic messages are reaching the subscriber. the /sync_topic subscriber is not receiving the data as it is in a different partition from the corresponding publisher. [info] [1612972054.995410057] [sync_async_subscriber]: i heard: 'async: hello, world! 10' [info] [1612972055.995396561] [sync_async_subscriber]: i heard: 'async: hello, world! 11' [info] [1612972056.995473953] [sync_async_subscriber]: i heard: 'async: hello, world! 12' configuring a service and a client ï services and clients have a publisher and a subscriber each, that communicate through two different topics. for example, for a service named ping there is: a service subscriber listening to requests on /rq/ping . a service publisher sending responses on /rr/ping . a client publisher sending requests on /rq/ping . a client subscriber listening to responses on /rr/ping . although you can use these topic names to set the configuration profiles on the xml, sometimes you may wish to apply the same profile to all services or clients on a node. instead of copying the same profile with all topic names generated for all services, you can just create a publisher and subscriber profile pair named service . the same can be done for clients creating a pair named client . create the nodes with the service and client ï start creating the node with the service. add a new source file named src/ping_service.cpp on your package with the following content: #include <memory> #include "rclcpp/rclcpp.hpp" #include "example_interfaces/srv/trigger.hpp" /** * service action: responds with success=true and prints the request on the console */ void ping ( const std :: shared_ptr < example_interfaces :: srv :: trigger :: request > request , std :: shared_ptr < example_interfaces :: srv :: trigger :: response > response ) { // the request data is unused ( void ) request ; // build the response response -> success = true ; // log to the console rclcpp_info ( rclcpp :: get_logger ( "ping_server" ), "incoming request" ); rclcpp_info ( rclcpp :: get_logger ( "ping_server" ), "sending back response" ); } int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); // create the node and the service std :: shared_ptr < rclcpp :: node > node = rclcpp :: node :: make_shared ( "ping_server" ); rclcpp :: service < example_interfaces :: srv :: trigger >:: sharedptr service = node -> create_service < example_interfaces :: srv :: trigger > ( "ping" , & ping ); // log that the service is ready rclcpp_info ( rclcpp :: get_logger ( "ping_server" ), "ready to serve." ); // run the node rclcpp :: spin ( node ); rclcpp :: shutdown (); } create the client in a file named src/ping_client.cpp with the following content: #include <chrono> #include <memory> #include "rclcpp/rclcpp.hpp" #include "example_interfaces/srv/trigger.hpp" using namespace std :: chrono_literals ; int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); // create the node and the client std :: shared_ptr < rclcpp :: node > node = rclcpp :: node :: make_shared ( "ping_client" ); rclcpp :: client < example_interfaces :: srv :: trigger >:: sharedptr client = node -> create_client < example_interfaces :: srv :: trigger > ( "ping" ); // create a request auto request = std :: make_shared < example_interfaces :: srv :: trigger :: request > (); // wait for the service to be available while ( ! client -> wait_for_service ( 1 s )) { if ( ! rclcpp :: ok ()) { rclcpp_error ( rclcpp :: get_logger ( "ping_client" ), "interrupted while waiting for the service. exiting." ); return 0 ; } rclcpp_info ( rclcpp :: get_logger ( "ping_client" ), "service not available, waiting again..." ); } // now that the service is available, send the request rclcpp_info ( rclcpp :: get_logger ( "ping_client" ), "sending request" ); auto result = client -> async_send_request ( request ); // wait for the result and log it to the console if ( rclcpp :: spin_until_future_complete ( node , result ) == rclcpp :: futurereturncode :: success ) { rclcpp_info ( rclcpp :: get_logger ( "ping_client" ), "response received" ); } else { rclcpp_error ( rclcpp :: get_logger ( "ping_client" ), "failed to call service ping" ); } rclcpp :: shutdown (); return 0 ; } open the cmakelists.txt file and add two new executables ping_service and ping_client : find_package ( example_interfaces required ) add_executable ( ping_service src/ping_service.cpp ) ament_target_dependencies ( ping_service example_interfaces rclcpp ) add_executable ( ping_client src/ping_client.cpp ) ament_target_dependencies ( ping_client example_interfaces rclcpp ) install ( targets ping_service destination lib/ { project_name } ) install ( targets ping_client destination lib/ { project_name } ) finally, build the package. create the xml profiles for the service and client ï create a file with name ping.xml with the following content: <?xml version="1.0" encoding="utf-8" ?> <profiles xmlns= "http://www.eprosima.com/xmlschemas/fastrtps_profiles" > <!-- default publisher profile --> <publisher profile_name= "default_publisher" is_default_profile= "true" > <historymemorypolicy> dynamic </historymemorypolicy> </publisher> <!-- default subscriber profile --> <subscriber profile_name= "default_subscriber" is_default_profile= "true" > <historymemorypolicy> dynamic </historymemorypolicy> </subscriber> <!-- service publisher is sync --> <publisher profile_name= "service" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> synchronous </kind> </publishmode> </qos> </publisher> <!-- client publisher is async --> <publisher profile_name= "client" > <historymemorypolicy> dynamic </historymemorypolicy> <qos> <publishmode> <kind> asynchronous </kind> </publishmode> </qos> </publisher> </profiles> this configuration file sets the publication mode to synchronous on the service and to asynchronous on the client. note that we are only defining the publisher profiles for both the service and the client, but subscriber profiles could be provided too. execute the nodes ï open two terminals and source the setup files on each one. then set the required environment variables for the xml to be loaded: linux macos windows export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/ping.xml export rmw_implementation=rmw_fastrtps_cpp export rmw_fastrtps_use_qos_from_xml=1 export fastrtps_default_profiles_file=path/to/ping.xml set rmw_implementation=rmw_fastrtps_cpp set rmw_fastrtps_use_qos_from_xml=1 set fastrtps_default_profiles_file=path/to/ping.xml on the first terminal run the service node. ros2 run sync_async_node_example_cpp ping_service you should see the service waiting for requests: [info] [1612977403.805799037] [ping_server]: ready to serve. on the second terminal, run the client node. ros2 run sync_async_node_example_cpp ping_client you should see the client sending the request and receiving the response: [info] [1612977404.805799037] [ping_client]: sending request [info] [1612977404.825473835] [ping_client]: response received at the same time, the output in the server console has been updated: [info] [1612977403.805799037] [ping_server]: ready to serve. [info] [1612977404.807314904] [ping_server]: incoming request [info] [1612977404.836405125] [ping_server]: sending back response other versions v: jazzy releases jazzy (latest) iron humble galactic (eol) foxy (eol) eloquent (eol) dashing (eol) crystal (eol) in development rolling