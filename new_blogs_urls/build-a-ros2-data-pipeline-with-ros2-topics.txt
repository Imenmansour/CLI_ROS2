skip to content in this tutorial ill show you how you can chain ros2 topics and thus build a data pipeline through several nodes. this is a pretty common use case in robotics: you get some data from a sensor, and you need to pass it through several parts of your applications. each part needs the data to do its own thing, and some parts may modify the data for other parts as well. for this example well create 3 nodes: node 1 (pipeline_step_1): create a random float number between 0 and 10, and publish it. node 2 (pipeline_step_2): get this number, multiply it by 2, and publish it. node 3 (pipeline_step_3): get this number, round it, and publish it. heres the graph well get at the end: first well write the 3 nodes, then build them, test them, and create a launch file to start them together. you want to learn ros2 efficiently? check out ros2 for beginners and learn ros2 step by step, in 1 week. >> watch this video as an additional resource to this article: after watching the video, subscribe to the robotics back-end youtube channel so you dont miss the next tutorials! table of contents toggle write the nodes data pipeline step 1 in this node well create a random float number between 0 and 10, and publish it on the data_1 topic. here i chose to write the node in python. plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 import random class node1 ( node ) : def __init__ ( self ) : super () . __init__ ( "pipeline_step_1" ) self.pub_ = self. create_publisher ( float64, "data_1" , 10 ) self.timer_ = self. create_timer ( 1.0 , self.publish_data ) def publish_data ( self ) : msg = float64 () msg.data = random. uniform ( 0.0 , 10.0 ) self. get_logger () . info ( "published: " + str ( msg.data )) self.pub_. publish ( msg ) def main ( args= none ) : rclpy. init ( args=args ) node = node1 () rclpy. spin ( node ) rclpy. shutdown () if __name__ == "__main__" : main () #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 import random class node1(node): def __init__(self): super().__init__("pipeline_step_1") self.pub_ = self.create_publisher(float64, "data_1", 10) self.timer_ = self.create_timer(1.0, self.publish_data) def publish_data(self): msg = float64() msg.data = random.uniform(0.0, 10.0) self.get_logger().info("published: " + str(msg.data)) self.pub_.publish(msg) def main(args=none): rclpy.init(args=args) node = node1() rclpy.spin(node) rclpy.shutdown() if __name__ == "__main__": main() #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 import random class node1(node): def __init__(self): super().__init__("pipeline_step_1") self.pub_ = self.create_publisher(float64, "data_1", 10) self.timer_ = self.create_timer(1.0, self.publish_data) def publish_data(self): msg = float64() msg.data = random.uniform(0.0, 10.0) self.get_logger().info("published: " + str(msg.data)) self.pub_.publish(msg) def main(args=none): rclpy.init(args=args) node = node1() rclpy.spin(node) rclpy.shutdown() if __name__ == "__main__": main() if youre not that confident with this code, check out how to write a minimal ros2 node in python , and also how to write a ros2 python publisher . here we use random. uniform () random.uniform() to get the random float number we want to start with. with the timer we create, we publish on the data_1 topic every 1 second  so, at 1 hz. and we also print on the terminal what weve just published, so it will be easier to debug. data pipeline step 2 this node will subscribe to the data_1 topic, process/transform the data, and publish the new data to the data_2 topic. here im writing the node in cpp, because well, ros2 communications are language agnostic, so you can use any language you want for your nodes. plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter #include "rclcpp/rclcpp.hpp" #include "example_interfaces/msg/float64.hpp" class node2 : public rclcpp::node { public : node2 () : node ( "pipeline_step_2" ) { pub_ = this - > create_publisher < example_interfaces::msg::float64 >( "data_2" , 10 ) ; sub_ = this - > create_subscription < example_interfaces::msg::float64 >( "data_1" , 10, std:: bind ( &node2::callbackdata, this , std::placeholders::_1 )) ; } private : void callbackdata ( const example_interfaces::msg::float64::sharedptr msg ) { auto new_msg = example_interfaces::msg:: float64 () ; new_msg. data = msg- > data * 2.0 ; rclcpp_info ( this - > get_logger () , "received: %lf, published: %lf" , msg- > data, new_msg. data ) ; pub_- > publish ( new_msg ) ; } rclcpp::publisher < example_interfaces::msg::float64 > ::sharedptr pub_; rclcpp::subscription < example_interfaces::msg::float64 > ::sharedptr sub_; } ; int main ( int argc, char **argv ) { rclcpp:: init ( argc, argv ) ; auto node = std::make_shared < node2 >() ; rclcpp:: spin ( node ) ; rclcpp:: shutdown () ; return 0; } #include "rclcpp/rclcpp.hpp" #include "example_interfaces/msg/float64.hpp" class node2 : public rclcpp::node { public: node2() : node("pipeline_step_2") { pub_ = this->create_publisher<example_interfaces::msg::float64>("data_2", 10); sub_ = this->create_subscription<example_interfaces::msg::float64>( "data_1", 10, std::bind(&node2::callbackdata, this, std::placeholders::_1)); } private: void callbackdata(const example_interfaces::msg::float64::sharedptr msg) { auto new_msg = example_interfaces::msg::float64(); new_msg.data = msg->data * 2.0; rclcpp_info(this->get_logger(), "received: %lf, published: %lf", msg->data, new_msg.data); pub_->publish(new_msg); } rclcpp::publisher<example_interfaces::msg::float64>::sharedptr pub_; rclcpp::subscription<example_interfaces::msg::float64>::sharedptr sub_; }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared<node2>(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } #include "rclcpp/rclcpp.hpp" #include "example_interfaces/msg/float64.hpp" class node2 : public rclcpp::node { public: node2() : node("pipeline_step_2") { pub_ = this->create_publisher<example_interfaces::msg::float64>("data_2", 10); sub_ = this->create_subscription<example_interfaces::msg::float64>( "data_1", 10, std::bind(&node2::callbackdata, this, std::placeholders::_1)); } private: void callbackdata(const example_interfaces::msg::float64::sharedptr msg) { auto new_msg = example_interfaces::msg::float64(); new_msg.data = msg->data * 2.0; rclcpp_info(this->get_logger(), "received: %lf, published: %lf", msg->data, new_msg.data); pub_->publish(new_msg); } rclcpp::publisher<example_interfaces::msg::float64>::sharedptr pub_; rclcpp::subscription<example_interfaces::msg::float64>::sharedptr sub_; }; int main(int argc, char **argv) { rclcpp::init(argc, argv); auto node = std::make_shared<node2>(); rclcpp::spin(node); rclcpp::shutdown(); return 0; } if youre not that confident with this code, check out how to write a minimal ros2 node in cpp . here we create a publisher (to data_2) as well as a subscriber (to data_1). in the data_1 topic callback, we: process the data and transform it, here by multiplying it by 2. create a new float64 message and fill it with this new data. publish the data to the data_2 topic. print what we received and what we published to make debugging/monitoring easier. note that we didnt create any rate to publish on the data_2 topic, we directly publish from the callback function of the data_1 topic. data pipeline step 3 the final node of our pipeline: this one will subscribe to the data_2 topic, process/transform the data, and publish the new data to the data_3 topic. and ill write this node in python again. plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 from example_interfaces.msg import int64 class node3 ( node ) : def __init__ ( self ) : super () . __init__ ( "pipeline_step_3" ) self.pub_ = self. create_publisher ( int64, "data_3" , 10 ) self.sub_ = self. create_subscription ( float64, "data_2" , self.callback_data, 10 ) def callback_data ( self, msg ) : new_msg = int64 () new_msg.data = round ( msg.data ) self. get_logger () . info ( "received: " + str ( msg.data ) + ", published: " + str ( new_msg.data )) self.pub_. publish ( new_msg ) def main ( args= none ) : rclpy. init ( args=args ) node = node3 () rclpy. spin ( node ) rclpy. shutdown () if __name__ == "__main__" : main () #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 from example_interfaces.msg import int64 class node3(node): def __init__(self): super().__init__("pipeline_step_3") self.pub_ = self.create_publisher(int64, "data_3", 10) self.sub_ = self.create_subscription( float64, "data_2", self.callback_data, 10) def callback_data(self, msg): new_msg = int64() new_msg.data = round(msg.data) self.get_logger().info("received: " + str(msg.data) + ", published: " + str(new_msg.data)) self.pub_.publish(new_msg) def main(args=none): rclpy.init(args=args) node = node3() rclpy.spin(node) rclpy.shutdown() if __name__ == "__main__": main() #!/usr/bin/env python3 import rclpy from rclpy.node import node from example_interfaces.msg import float64 from example_interfaces.msg import int64 class node3(node): def __init__(self): super().__init__("pipeline_step_3") self.pub_ = self.create_publisher(int64, "data_3", 10) self.sub_ = self.create_subscription( float64, "data_2", self.callback_data, 10) def callback_data(self, msg): new_msg = int64() new_msg.data = round(msg.data) self.get_logger().info("received: " + str(msg.data) + ", published: " + str(new_msg.data)) self.pub_.publish(new_msg) def main(args=none): rclpy.init(args=args) node = node3() rclpy.spin(node) rclpy.shutdown() if __name__ == "__main__": main() so, we have a publisher to data_3 and a subscriber to data_2. here again we do everything in the data_2 callback function: process the data and modify it: here we round it and we get an integer instead of a float number. create a new message with a different type. we received a float64 data, now were publishing an int64. publish the new data. log. the most important point here is that were using a different data type to pass the message to the next step of the pipeline. note: as this is the last step of our pipeline example, we could just print the result with a log, and not publish it. in your own application with your own nodes and data, youll have a good idea of what you should do. build and run the ros2 data pipeline application add executables in setup.py for python nodes, and in cmakelists.txt for cpp nodes. then compile from your ros2 workspace with colcon build colcon build . run the app in 3 different terminals open 3 terminals/sessions. if you already had 3 open terminals, make sure to source your ros2 workspace in each one before you continue. lets start all 3 nodes and see what we get. terminal 1: plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter  ros2 run ros2_tutorials_py node_1 ... [info] [1594190744. 946266831 ] [pipeline_step_1]: published: 7. 441288072582843 [info] [1594190745. 950362887 ] [pipeline_step_1]: published: 9. 968039333074264 [info] [1594190746. 944258673 ] [pipeline_step_1]: published: 8. 848880026052129 [info] [1594190747. 945936611 ] [pipeline_step_1]: published: 1. 8232649263149414 ...  ros2 run ros2_tutorials_py node_1 ... [info] [1594190744.946266831] [pipeline_step_1]: published: 7.441288072582843 [info] [1594190745.950362887] [pipeline_step_1]: published: 9.968039333074264 [info] [1594190746.944258673] [pipeline_step_1]: published: 8.848880026052129 [info] [1594190747.945936611] [pipeline_step_1]: published: 1.8232649263149414 ...  ros2 run ros2_tutorials_py node_1 ... [info] [1594190744.946266831] [pipeline_step_1]: published: 7.441288072582843 [info] [1594190745.950362887] [pipeline_step_1]: published: 9.968039333074264 [info] [1594190746.944258673] [pipeline_step_1]: published: 8.848880026052129 [info] [1594190747.945936611] [pipeline_step_1]: published: 1.8232649263149414 ... terminal 2: plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter  ros2 run ros2_tutorials_cpp node_2 ... [info] [1594190744. 944747967 ] [pipeline_step_2]: received: 7. 441288 , published: 14. 882576 [info] [1594190745. 949126317 ] [pipeline_step_2]: received: 9. 968039 , published: 19. 936079 [info] [1594190746. 943588170 ] [pipeline_step_2]: received: 8. 848880 , published: 17. 697760 [info] [1594190747. 944386405 ] [pipeline_step_2]: received: 1. 823265 , published: 3. 646530 ...  ros2 run ros2_tutorials_cpp node_2 ... [info] [1594190744.944747967] [pipeline_step_2]: received: 7.441288, published: 14.882576 [info] [1594190745.949126317] [pipeline_step_2]: received: 9.968039, published: 19.936079 [info] [1594190746.943588170] [pipeline_step_2]: received: 8.848880, published: 17.697760 [info] [1594190747.944386405] [pipeline_step_2]: received: 1.823265, published: 3.646530 ...  ros2 run ros2_tutorials_cpp node_2 ... [info] [1594190744.944747967] [pipeline_step_2]: received: 7.441288, published: 14.882576 [info] [1594190745.949126317] [pipeline_step_2]: received: 9.968039, published: 19.936079 [info] [1594190746.943588170] [pipeline_step_2]: received: 8.848880, published: 17.697760 [info] [1594190747.944386405] [pipeline_step_2]: received: 1.823265, published: 3.646530 ... terminal 3: plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter  ros2 run ros2_tutorials_py node_3 ... [info] [1594190744. 955152638 ] [pipeline_step_3]: received: 14. 882576145165686 , published: 15 [info] [1594190745. 951406026 ] [pipeline_step_3]: received: 19. 93607866614853 , published: 20 [info] [1594190746. 944646754 ] [pipeline_step_3]: received: 17. 697760052104258 , published: 18 [info] [1594190747. 946918714 ] [pipeline_step_3]: received: 3. 646529852629883 , published: 4 ...  ros2 run ros2_tutorials_py node_3 ... [info] [1594190744.955152638] [pipeline_step_3]: received: 14.882576145165686, published: 15 [info] [1594190745.951406026] [pipeline_step_3]: received: 19.93607866614853, published: 20 [info] [1594190746.944646754] [pipeline_step_3]: received: 17.697760052104258, published: 18 [info] [1594190747.946918714] [pipeline_step_3]: received: 3.646529852629883, published: 4 ...  ros2 run ros2_tutorials_py node_3 ... [info] [1594190744.955152638] [pipeline_step_3]: received: 14.882576145165686, published: 15 [info] [1594190745.951406026] [pipeline_step_3]: received: 19.93607866614853, published: 20 [info] [1594190746.944646754] [pipeline_step_3]: received: 17.697760052104258, published: 18 [info] [1594190747.946918714] [pipeline_step_3]: received: 3.646529852629883, published: 4 ... thanks to the logs you can see where the data goes, when it is received and sent, and how it is processed. now, if you get the list of all topics running in your graph with ros2 topic list : plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter  ros2 topic list /data_1 /data_2 /data_3 /parameter_events /rosout  ros2 topic list /data_1 /data_2 /data_3 /parameter_events /rosout  ros2 topic list /data_1 /data_2 /data_3 /parameter_events /rosout we find the topics data_1, data_2 and data_3. so, this is really great. from there you can: from the terminal, listen to any topic with ros2 topic echo and see whats going on. plug any new node to any of those topics. for example you want to make a more complex data pipeline: another node can subscribe to data_2, and then process it independently. start your data pipeline with a ros2 launch file for developing and debugging, starting your nodes from the terminal is great. however, if you want to create a real ros2 application, youll have to use launch files. on top of the advantages of using a ros2 launch file, youll also be able to start all your nodes at the exact same time, so all the steps of the pipeline will start working at the same time. so, lets write a simple launch file to start all 3 nodes. plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter from launch import launchdescription from launch_ros.actions import node def generate_launch_description () : ld = launchdescription () node_1 = node ( package= "ros2_tutorials_py" , executable= "node_1" ) node_2 = node ( package= "ros2_tutorials_cpp" , executable= "node_2" ) node_3 = node ( package= "ros2_tutorials_py" , executable= "node_3" ) ld. add_action ( node_1 ) ld. add_action ( node_2 ) ld. add_action ( node_3 ) return ld from launch import launchdescription from launch_ros.actions import node def generate_launch_description(): ld = launchdescription() node_1 = node( package="ros2_tutorials_py", executable="node_1" ) node_2 = node( package="ros2_tutorials_cpp", executable="node_2" ) node_3 = node( package="ros2_tutorials_py", executable="node_3" ) ld.add_action(node_1) ld.add_action(node_2) ld.add_action(node_3) return ld from launch import launchdescription from launch_ros.actions import node def generate_launch_description(): ld = launchdescription() node_1 = node( package="ros2_tutorials_py", executable="node_1" ) node_2 = node( package="ros2_tutorials_cpp", executable="node_2" ) node_3 = node( package="ros2_tutorials_py", executable="node_3" ) ld.add_action(node_1) ld.add_action(node_2) ld.add_action(node_3) return ld compile and run this launch file  heres a ros2 launch file tutorial if you dont know how to do. plain text copy to clipboard open code in new window enlighterjs 3 syntax highlighter  ros2 launch my_robot_bringup data_pipeline.launch.py [info] [launch]: all log files can be found below /home/ed/.ros/log/ 2020 - 07 - 08 - 09 - 55 - 37 - 919871 -ed-vm- 11593 [info] [launch]: default logging verbosity is set to info [info] [node_1- 1 ]: process started with pid [ 11595 ] [info] [node_2- 2 ]: process started with pid [ 11597 ] [info] [node_3- 3 ]: process started with pid [ 11599 ] [node_1- 1 ] [info] [1594194939. 304693502 ] [pipeline_step_1]: published: 0. 9131821923863725 [node_2- 2 ] [info] [1594194939. 305641498 ] [pipeline_step_2]: received: 0. 913182 , published: 1. 826364 [node_3- 3 ] [info] [1594194939. 314622095 ] [pipeline_step_3]: received: 1. 826364384772745 , published: 2 [node_1- 1 ] [info] [1594194940. 292584583 ] [pipeline_step_1]: published: 6. 724756051691409 [node_2- 2 ] [info] [1594194940. 293238316 ] [pipeline_step_2]: received: 6. 724756 , published: 13. 449512 [node_3- 3 ] [info] [1594194940. 294448648 ] [pipeline_step_3]: received: 13. 449512103382817 , published: 13  ros2 launch my_robot_bringup data_pipeline.launch.py [info] [launch]: all log files can be found below /home/ed/.ros/log/2020-07-08-09-55-37-919871-ed-vm-11593 [info] [launch]: default logging verbosity is set to info [info] [node_1-1]: process started with pid [11595] [info] [node_2-2]: process started with pid [11597] [info] [node_3-3]: process started with pid [11599] [node_1-1] [info] [1594194939.304693502] [pipeline_step_1]: published: 0.9131821923863725 [node_2-2] [info] [1594194939.305641498] [pipeline_step_2]: received: 0.913182, published: 1.826364 [node_3-3] [info] [1594194939.314622095] [pipeline_step_3]: received: 1.826364384772745, published: 2 [node_1-1] [info] [1594194940.292584583] [pipeline_step_1]: published: 6.724756051691409 [node_2-2] [info] [1594194940.293238316] [pipeline_step_2]: received: 6.724756, published: 13.449512 [node_3-3] [info] [1594194940.294448648] [pipeline_step_3]: received: 13.449512103382817, published: 13  ros2 launch my_robot_bringup data_pipeline.launch.py [info] [launch]: all log files can be found below /home/ed/.ros/log/2020-07-08-09-55-37-919871-ed-vm-11593 [info] [launch]: default logging verbosity is set to info [info] [node_1-1]: process started with pid [11595] [info] [node_2-2]: process started with pid [11597] [info] [node_3-3]: process started with pid [11599] [node_1-1] [info] [1594194939.304693502] [pipeline_step_1]: published: 0.9131821923863725 [node_2-2] [info] [1594194939.305641498] [pipeline_step_2]: received: 0.913182, published: 1.826364 [node_3-3] [info] [1594194939.314622095] [pipeline_step_3]: received: 1.826364384772745, published: 2 [node_1-1] [info] [1594194940.292584583] [pipeline_step_1]: published: 6.724756051691409 [node_2-2] [info] [1594194940.293238316] [pipeline_step_2]: received: 6.724756, published: 13.449512 [node_3-3] [info] [1594194940.294448648] [pipeline_step_3]: received: 13.449512103382817, published: 13 and well, your data pipeline is now fully ready! for production you may remove the info logs and only print the warn logs. conclusion you can now build a complete data pipeline using ros2 nodes and topics. the ros2 architecture and tools bring you many advantages. you can: write any step or the pipeline (node) in any language you want. debug each step from the terminal with the ros2 topic ros2 topic command line tool. start only a few steps of your pipeline. add new steps (nodes) at the beginning, end, or anywhere else in the pipeline. want to learn how to program with ros2? don't miss this opportunity: [new] ros 2 book or, learn with a video course want to learn ros2? [new] ros 2 book or, learn with a video course we use s on our website to give you the most relevant experience by remembering your preferences and repeat visits. by clicking accept all, you consent to the use of all the s. however, you may visit " settings" to provide a controlled consent.  settings accept all manage consent close  overview this website uses s to improve your experience while you navigate through the website. out of these, the s that are categorized as necessary are stored on your browser as they are essential for the working of basic functionalities of the ... necessary necessary always enabled necessary s are absolutely essential for the website to function properly. these s ensure basic functionalities and security features of the website, anonymously.  duration description lawinfo-checkbox-analytics 11 months this  is set by gdpr  consent plugin. the  is used to store the user consent for the s in the category "analytics". lawinfo-checkbox-functional 11 months the  is set by gdpr  consent to record the user consent for the s in the category "functional". lawinfo-checkbox-necessary 11 months this  is set by gdpr  consent plugin. the s is used to store the user consent for the s in the category "necessary". lawinfo-checkbox-others 11 months this  is set by gdpr  consent plugin. the  is used to store the user consent for the s in the category "other. lawinfo-checkbox-performance 11 months this  is set by gdpr  consent plugin. the  is used to store the user consent for the s in the category "performance". viewed__policy 11 months the  is set by the gdpr  consent plugin and is used to store whether or not user has consented to the use of s. it does not store any personal data. functional functional functional s help to perform certain functionalities like sharing the content of the website on social media platforms, collect feedbacks, and other third-party features. performance performance performance s are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors. analytics analytics analytical s are used to understand how visitors interact with the website. these s help provide information on metrics the number of visitors, bounce rate, traffic source, etc.    s are used to provide visitors with relevant ads and  campaigns. these s track visitors across websites and collect information to provide customized ads. others others other uncategorized s are those that are being analyzed and have not been classified into a category as yet. save & accept learn ros2 in a week check out the course here