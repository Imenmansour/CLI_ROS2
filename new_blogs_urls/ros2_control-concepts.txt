skip to main content on this page why do we need ros2_control?  today were going to learn how to solve a problem that literally every robot has, and that's control . a core part of every robot is to take in some kind of input (from an operator or the environment), do some thinking, and drive an actuator - whether that's a motor, a hydraulic system, or something else. there are many different kinds of actuators and interfaces out there, and many different control methodologies that we use to use to solve problems with them. but within this huge universe of options, theres actually a lot of commonality, and if we dont have some kind of standardised system - if were just writing a custom controller and custom interface for every application - we end up wasting time rewriting things and solving problems that people have solved hundreds of times before instead what we want is a framework where we can write the drivers for different hardware platforms, and the algorithms for different control methodologies, and have these speak a common language so we can pick and choose what we need. you might think that this is a problem well suited to ros topics - just create some standard messages, write nodes for the controllers and drivers, and youre done! one problem with this approach is that although topics are generally pretty fast, we want something like this to run really fast, there should be no delay between the controller and the driver. that's where ros2_control comes in. the ros2_control framework is a powerful and complex beast, so to understand it were going to have to take it step by step. it might be tempting to give up and say it would be quicker to just write this from scratch and although maybe it would be (probably not), the power of ros2_control is not just that it can make individual projects simpler, but that it makes reusing code, upgrading, and modifying systems way easier. in this tutorial well look at how ros2_control works, and how to use it in a gazebo simulation, and then in the next tutorial well get it up and running on a real robot so we can drive it around. controller manager  at the centre of it all we have something called the controller manager. its going to find all the bits of code for our hardware drivers and our controllers and link them together. to achieve this, it uses a plugin system - so each of these things isnt running its own executable, its just a library that is loaded up at runtime and has a set of functions that will link in to the system. hardware interfaces  lets take a look at the hardware side first. different hardware needs to be controlled differently. you might have two very similar-looking robots, but ones motors speak via serial, and the other via can bus. one might let you control speed and position, the other only speed, or speed and torque. one might have a single comms interface for all motors, the other might have an interface per motor. whatever our hardware looks like, to use ros2_control with it, we need something called a hardware interface (sometimes called a hardware component ). this is a bit of code that talks to the hardware and exposes it in the ros2_control standard way. ideally if youve bought a robot, the creator or someone else online will have written the hardware interface for you. if youre following along with my build series youll be able to use the one ive written, but otherwise you might need to write one yourself. i may cover that in a future tutorial, but it's not currently planned. the hardware interface acts as an abstraction so that as users, all we need to understand is the way it represents our hardware, which is through command interfaces and state interfaces . command interfaces are things we can control, and state interfaces are things we can only monitor. as an example, on the robot i'm building the only thing we can control is the velocity of the motors, so my hardware interface will have two command interfaces, both velocity control, one for each motor. and what state interfaces will it have? well, using the encoders we can measure both the velocity and the position of the wheels. so it will have four state interfaces, position and velocity for each motor. if we had other things to measure like torque or current (or even a non-motor sensor like battery level) these could be added in too. below is a preview of what well see later on. with the hardware interface loaded, we can see the two command interfaces and the four state interfaces. at this level of abstraction, there is really no understanding of what the robot is. it doesnt matter if this is a two-wheeled diff drive robot, or a 2 degree of freedom robotic arm that is for some reason only speed controlled - all we see are these six interfaces. one robot may have multiple hardware interfaces, each of which can have multiple command and state interfaces. there are many reasons you might have this - perhaps you have a robot arm mounted on a mobile base, each with separate motor control systems, or perhaps each of your motors is fully independently controlled with their own driver instance. to deal with this, the controller manager uses something called the resource manager which gathers up all the hardware interfaces and expose them all together, so the controllers just see a big list of command and state interfaces. and how does the controller/resource manager know  the hardware interfaces? because theyre tied pretty closely to the robots hardware design, we put it into the urdf using a <ros2_control> tag. well take a closer look at this later. so thats the hardware interfaces, what  the controllers? controllers  the controllers are how the rest of the ros ecosystem interacts with ros2_control. on one end theyll be listening to a ros topic for control input - could be joint positions or mobile body velocities - they take this input and use some kind of algorithm to figure out the appropriate actuator speeds, positions, etc, and send that to the appropriate hardware interfaces. they can also publish to ros topics for command feedback or state information they receive from the hardware, and a single controller can pass information in either or both directions. this last point can be a little confusing - it's common to have a controller that doesn't actually "control" anything, it just publishes sensor/feedback data. here the controller managers job is to take the controllers its asked to load, and match them up with the right command and state interfaces that the resource manager is exposing. to set up the controllers we write a yaml file with the various parameters we need, and pass that in to the controller manager. once this is all loaded up, we can tell it to start and stop the controllers as needed. just like we can have multiple hardware interfaces, we can also have multiple controllers in one robot, as long as they dont both want to claim the same resources , theyre not trying to command the same (or similar) interface. they can share state interfaces though, since theyre read-only. while the hardware interfaces are going to be made specifically for different robot hardware , the controllers are going to be dependent on the robot application , and since there are a few common applications, the ros2_controllers package provides a bunch of controllers that should cover most peoples needs. the project we are working on in these tutorials is a differential drive robot, so naturally we'll be using the diff_drive_controller , but of course a robot arm or something else will require a different controller. and if there isn't an appropriate controller available, we can write our own! note that while the primary controller we'll be using in this project is the diff_drive_controller, we'll actually be using a second controller - a joint_state_broadcaster. this controller is one of those "non-controlling" ones and is used to ensure our wheel transforms are generated correctly. more on this later. running the controller manager  ok, so we know weve got our hardware interfaces on one side, our controllers on the other side, and a controller manager in the middle. so how do we run this thing? there are kind of two ways to run a controller manager. the normal (and simpler) way to do it is with the ros2_control_node provided by the controller_manager package, but you can also write your own node and instantiate the controller manager inside it. we'll get to see a glimpse of that soon, because the gazebo_ros2_control plugin runs its own controller manager, but when we run it on our robot in the next tutorial we'll learn how to use the standalone one. either way, we need to provide it with the details of the hardware interfaces (usually via urdf) and the controllers (usually via yaml parameters). then, once the controller manager is running, we need to interact with it to do things like checking the hardware interfaces and starting the controllers. there are a few different ways we can do these interactions: it exposes some services that we can call it provides the ros2 control command line tool to simplify calling the services it provides some nodes which will also call the services when they are executed using these tools we can start and stop and reconfigure the controllers. each of methods has its pros and cons which well briefly discuss when we use them later in the tutorial. testing it out in simulation  so thats the theory, lets start putting it into practice by upgrading our gazebo robot simulation to use ros2_control! installing dependencies  first, we need to install some packages. we want: sudo apt install ros-foxy-ros2-control ros-foxy-ros2-controllers ros-foxy-gazebo-ros2-control update urdf  now lets update our urdf - ill be continuing the example urdf from the rest of this tutorial series, but it shouldnt be too hard to follow along if youre just joining in. you might remember that we had a file called gazebo_control.xacro which handled the gazebo control code. were going to create a new file called ros2_control.xacro and then in our robot.urdf.xacro , well comment out the old one and add in the new one. <!-- <xacro:include filename="gazebo_control.xacro" /> --> < xacro: include filename = " ros2_control.xacro " /> make sure we start by adding our normal <xml> and <robot> tags, they can be copied from one of the other xacro files. so what needs to go in this file? for now, well have two main tags. there is a <ros2_control> tag, which will have the details of the hardware interface (for the controller manager) and then a <gazebo> tag which will tell gazebo to load up the extra code that it needs. first up well fill in the ros2_control tag. we need to give it a name, ill call mine "gazebosystem" , and set the type, which is "system" . the other types are actuator and sensor which can be used when the hardware is a single actuator or sensor, but system is the most general. inside this, we add a <hardware> tag with a <plugin> tag inside that, and this is going to be the name of the hardware interface it needs to load up. this is a piece of code that has been installed and registered with ros separately, that will talk to gazebo just like a normal hardware interface talks to a motor controller. in this case, the name of the plugin we want to use is gazebo_ros2_control/gazebosystem , so we can put that in there. < ros2_control name = " gazebosystem " type = " system " > < hardware > < plugin > gazebo_ros2_control/gazebosystem </ plugin > </ hardware > </ ros2_control > now we need to specify which joints are to be controlled, so we make joint tags and set the name - in this case the joints that go from the base to the left and right wheels. we also need to declare which interfaces are being made available for that joint. as we saw earlier, were going to have one command interface for each wheel (velocity) with the option of specifying limits, and the two state interfaces (velocity/position). < ros2_control name = " gazebosystem " type = " system " > < hardware > < plugin > gazebo_ros2_control/gazebosystem </ plugin > </ hardware > < joint name = " left_wheel_joint " > < command_interface name = " velocity " > < param name = " min " > -10 </ param > < param name = " max " > 10 </ param > </ command_interface > < state_interface name = " position " /> < state_interface name = " velocity " /> </ joint > < joint name = " right_wheel_joint " > < command_interface name = " velocity " > < param name = " min " > -10 </ param > < param name = " max " > 10 </ param > </ command_interface > < state_interface name = " velocity " /> < state_interface name = " position " /> </ joint > </ ros2_control > thats the ros2_control tag done, weve told it the hardware interface to load and which joints to associate with. now we need to set up the <gazebo> tag. it begins similarly to gazebo_control.xacro , inside our <gazebo> tag we have a <plugin> tag. this time the plugin file name is libgazebo_ros2_control.so and we can give it a name, gazebo_ros2_control . this plugin is actually doing a few different things: loading up the stuff needed on the gazebo end to talk to the hardware interface running a controller manager finding the urdf provided by robot_state_publisher because it has the controller manager inside it, it still needs a yaml parameters file to know which controllers to load. to tell it, we need to add a tag called <parameters> and this will be the path to our yaml file. since we don't have that file yet, just leave it blank and we'll come back to it soon. < gazebo > < plugin filename = " libgazebo_ros2_control.so " name = " gazebo_ros2_control " > < parameters > ...to be filled in soon!... </ parameters > </ plugin > </ gazebo > controller config  up in our config directory, lets create a new file in our config directory called my_controllers.yaml . this file will be a fairly typical ros parameter file, if youre familiar with them. the first thing we need parameters for is the controller manager. two simple parameters to set are the update_rate which determines the rate the controllers will update at, and use_sim_time because we want to use this with a gazebo simulation. more confusing are the parameters that determine our controllers. we set the parameter name as the name we want to call our controller, then nested under it is the type of the controller. we need to make two controllers, a diff_drive_controller and a joint_state_broadcaster which we'll dive into next. i've named them diff_cont and joint_broad to keep things shorter. controller_manager : ros_parameters : update_rate : 30 use_sim_time : true diff_cont : type : diff_drive_controller/diffdrivecontroller joint_broad : type : joint_state_broadcaster/jointstatebroadcaster directly below the controller_manager section, we add sections for the parameters of our controllers. the diff_drive_controller has many different parameters to explore, but for now we'll just set the ones below. they are mostly self-explanatory except for use_stamped_vel which we'll take a closer look at in a future tutorial. the joint_state_broadcaster simply uses the wheel encoder positions to publish the /joint_states message that robot_state_publisher needs to generate the wheel transforms. for a mobile robot this is not all that important - we care more  the position of the robot in space than exactly how far each wheel has turned - but it is still nice to have. for a robot arm it is much more important. i have left its parameter block commented out as we won't be setting anything. note that we aren't setting use_sim_time on the controllers - it gets propagated down from the controller manager. ## directly below the controller_manager section diff_cont : ros__parameters : publish_rate : 30.0 # you can set this higher than the controller manager update rate, but it will be throttled base_frame_id : base_link left_wheel_names : [ 'left_wheel_joint' ] right_wheel_names : [ 'right_wheel_joint' ] wheel_separation : 0.35 wheel_radius : 0.05 use_stamped_vel : false # joint_broad: # ros__parameters: once weve finished our controller config, we can go back to our urdf and put in that url. to get the path to work nicely we can use a neat trick to find our package and then specify a relative path. remember to replace articubot_one with whatever you've called your package! < parameters > (find articubot_one)/config/my_controllers.yaml </ parameters > starting the controllers  we can rebuild with colcon to add our new file, then launch our sim just like in the other tutorials. you might notice that the gazebo window is printing out some slightly different content. this is a good chance for us to start using the ros2 control command line tool. if we type ros2 control and hit tab we can see all the options. the only one well use right now is list_hardware_interfaces and sure enough, we can see our hardware interfaces. its tempting to run list_controllers too, but (as far as i can tell) this will only work once the controllers have been loaded - so lets do that now. as mentioned earlier, theres a few ways we can do this. we can use the service call (which is fiddly), we can use the load_controller command we saw a second ago (which is good, but the syntax changed slightly between foxy and the newer versions, and also its trickier to use in launch files) or we can use the provided spawner script/node. let's try the spawner script. ros2 run controller_manager spawner.py diff_cont ros2 run controller_manager spawner.py joint_broad this should provide some feedback to let us know it started succesfully: and similarly we should see an indication on the gazebo tab that it started: getting teleop working  we can run teleop_twist_keyboard to drive it around, but we need to do it slightly differently this time. previously, the gazebo diff drive plugin was listening on /cmd_vel , which is what the teleop control was publishing to. the new controller will be listening on /diff_cont/cmd_vel_unstamped , so we need to remap the topic with the following command: ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/diff_cont/cmd_vel_unstamped note that if you didn't name your controller diff_cont you should substitute it with the name you used. normally, the diff_drive_controller is expecting a stamped twist (velocity) message ( twiststamped ) which we are disabling with that use_stamped_vel parameter. as mentioned earlier, we'll explore this in a future tutorial. we should now be able to drive our robot around again in gazebo, and of course we can fire up rviz to monitor everything. updating the launch file  running those spawner scripts each time is a bit of a pain, let's add them to our launch file ( launch_sim.launch.py ) so that they start automatically. diff_drive_spawner = node ( package = "controller_manager" , executable = "spawner.py" , arguments = [ "diff_cont" ] , ) joint_broad_spawner = node ( package = "controller_manager" , executable = "spawner.py" , arguments = [ "joint_broad" ] , ) # then at the bottom... return launchdescription ( [ rsp , gazebo , spawn_entity , # ... anything else you've added in here... diff_drive_spawner , joint_broad_spawner ] ) it's possible to set these up on delays to run after the robot spawner has run (see the version on github for details), or after a timer, but i have found that there is generally a long enough timeout that it is not an issue. the exception to this is sometimes the first time gazebo is launched after a boot it can take too long and the spawner times out. in this case you may need to kill and rerun it. conclusion  if we drive it around now we'll see that it basically works. if you pay close attention though, youll notice there are a few little things that are not quite right. before we start trying to use this updated simulation or go ahead with the physical robot, it's worth taking these extra steps. i've put them in their own post so if you're following along with the build series, you'll want to head there now. if you were just wanting an overview of ros2_control, i hope you found this helpful! if you have other questions or comments, there is a section below where you can join in the discussion over at the forums. why do we need ros2_control? controller manager hardware interfaces controllers running the controller manager testing it out in simulation installing dependencies update urdf controller config starting the controllers getting teleop working updating the launch file conclusion