improving fps on jetson orin hw with zed_ros2_wrapper software ros2 jetson , multi-camera fonticode may 2, 2023, 9:35am 1 hi, im currently developing on new nvidia jetson orin hardware i.e. nano8, nx16 and agx64 with dual cameras zed2i. the setup is: jetson linux 35.3.1 therefore jetpack 5.1.1 ( jetpack sdk 5.1.1 | nvidia developer ), zed sdk 4.0 and ros2 foxy with zed_ros2_wrapper (all locally installed). i would like to have a steady 25 - 30 fps on both color and depth for the 2 cameras with higher resolution. currently reaching ~20 fps on depth and ~10 fps on color (nx16) with: grab_resolution: vga grab_frame_rate: 60 pub_resolution: vga pub_frame_rate: 60 depth_mode: performance openni_depth_mode: true pos_tracking: disabled on agx64 i can reach the same performance with medium/hd720 but on nano8 even vga is quite slower. im most interested on making it work on nano8. finally, is there any tested setup to reach the aforementioned performance, that is, versions of jetson linux/zed sdk/ros2 or set of camera configurations? thank you in advance! myzhar may 2, 2023, 9:40am 2 hi @fonticode welcome to the stereolabs community. have you tried to lower the grab_frame_rate to 30 if your requirement is 23-30 fps? fonticode may 2, 2023, 10:00am 3 thank you @myzhar . yes i did, the performance is pretty much the same myzhar may 2, 2023, 10:11am 4 how are you measuring the fps? are you running rviz2 on the jetson? fonticode may 2, 2023, 10:29am 5 no im using rqt, ros cli or foxglove (with rosbridge) myzhar may 2, 2023, 1:41pm 6 rqt and rviz2 can take too much computing power and reduce the final performances, mainly on a nano. here are the expected fps on the orin nano when using the zed depth viewer: zed depth viewer hd720@60 performance: 60 hz quality: 20 hz ultra: 28 hz neural: 15 hz hd1080@30 performance: 30 hz quality: 13 hz ultra: 25 hz neural: 14 hz with the zed ros2 wrapper you can expect 2-3 fps lower values caused by the ros 2 middleware. fonticode may 2, 2023, 4:08pm 7 makes sense, by bag recording the topics and playing them back later i can visualize them at the actual frequency, with my previous settings, ive got: depth_registered ~30hz image_raw_color ~20hz fonticode may 8, 2023, 10:00am 8 hi @myzhar , after some further experiments i observed the following behaviors: when trying to launch both cameras with vga,30,ultra/performance on orin nx16 there is an imbalance between the two cameras, one publishes depth at 30hz the other at 15hz. if i try to set the resolution to 720,30,ultra, the first camera is initialized properly and runs, the second prints the following error message: [zed][error] [zed] cannot initialize the camera. try another resolution and does not recover, reaching detection timeout error (same with medium/auto). moreover by launching a single camera with the ros2 wrapper launcher i observed the following frequencies: ros2 (foxy) topic hz, launching zed2i.launch.py hd720@60 performance: 27 hz quality: 21 hz ultra: 20 hz neural: 13 hz hd1080@30 performance: 13 hz quality: 11 hz ultra: 11 hz neural: 9 hz bottom line: it seems that the only resolution to use 2 cameras at the same time is vga (with imbalance) the difference between the expected and achieved frequencies is quite large have you by any chance done similar experiments? should i try using the previous version of jetson linux with sdk 3.8 instead of 4.0? or maybe ros humble from a container? myzhar may 9, 2023, 8:08am 9 we are investigating this in the next few days. we have scheduled a massive jetson benchmarking section to have a better idea of the expected performances we will publish a  post with the results. tyrellcorp june 6, 2023, 9:11am 10 @myzhar hello, do you have an eta on this  post? thanks! 3 likes mpzed july 8, 2023, 4:19am 11 @myzhar any updates or news on this? frankly speaking we are happy with the hw of the zed 2i cams for prosessional and production use but the sw implementation and drivers on ros2 have extremely poor performance if for example compared with intel realsense sdk. even on the most recent hw like the nvidia orin series (like jetson orin nx 16) we struggle to run 2 cameras at 25 fps just computing the stereo depth using the performance setting under the ros2 wrapper. would be appreciated that you invest on that low level tuning rather than adding models to the framework which are nice for educational purposes but dont help the adoption for production and industrialized products. thanks, mp 2 likes