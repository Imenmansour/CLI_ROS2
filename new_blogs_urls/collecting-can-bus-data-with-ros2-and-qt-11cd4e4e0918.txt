open in app sign up sign in write sign up sign in collecting can bus data with ros 2 and qt tamas foldi  follow published in hcltechstarschema blog  6 min read  oct 25, 2023  listen share one obvious way to learn something new is to use stuff you already have. this was my thinking when i decided to invest my time in learning sensor fusion at the edge  more precisely, performing sensing and perception in ros 2 to see how autonomous vehicles work. i drive a tesla as a company car, and its outfitted with tons of cameras and sensors, so i dusted off my raspberries and got to wiring. looking at can frames and signals in my car was the first step in the effort to collect all required data. to meaningfully perform perception, we need sensing, and for sensing, we need sensors. avs typically use the following telemetry and sensor data to see and understand the vehicle and its surroundings: car telemetry like speed and distance to support odometry. these usually come from the can bus, the cars internal communication backbone; gps position signals, also usually coming through can bus; cameras like dash cams; lidar and radar point clouds. we need to fuse all these sensors to gain full awareness of our and surrounding objects position. thankfully, ros 2 has a lot of prebuilt packages that can do the heavy lifting, which helps me focus more on the collection and analysis rather than reinventing and reimplementing sensor fusing algorithms. collecting can bus signals i bought a cl1000 adapter to log the can bus signals. to connect it to my tesla 3, i ordered an obd2 16pin26bin adapter along with an obd2 adapter. wiring them up wasnt hard, but as its mentioned everywhere, do not forget to turn off your car before this step, otherwise, it can harm your vehicle. css electronics also has a nice blog post on how to connect their logger. i know, i need to clean my car more frequently. anyway, the logger simply connected to the teslas can bus. out of the box, the logger supports qtbased can bus analyzer tools like savvycan, so i was able to quickly check if the connection was ok: i was able to see can signals in savvycan in real time. the cl1000 already comes with a qt5 qtcanbus plugin that makes it easy to use with any qt application. the advantage of this qtcanbus  based connection was that i could use my mac for debugging and reverse engineering, as socketcan the standard can interface primarily works with linux. adding qt canbus support for ros 2 the next step on my list was to feed the data from the car to an ros 2 topic, decode it and dispatch it as standard messages like twist , navsatfix or diagnoticarray to make them available for standard sensor fusing libraries. i didnt find any ros 2 library that captures and decodes can frames the way i wanted, so i ended up building my own set of packages. i also couldnt find a standard can bus message type in ros 2, but ros 1 industrials canmsgsframe from https:github.comrosindustrialroscanopen  was love at first sight, so i used it as qcanbusframe.msg . ros2qtcanbusmsgsqcanbusframe, same as canmsgsframe from ros1 industrial to build the publisher node, i used libros2qt , a small library that provides a ros 2 executor that enables running qapplication and ros nodes from the same process. the processing nodes code is fairly straightforward: when a frame becomes available from qtcandevice, the code publishes it as a qcanbusframe message to the fromcanbus topic. publishing frames from qtcanbus callback decoding signals with dbc files the next step is to make sense of the data collected from the vehicle. so far, we have the frameid do not confuse this with ross frameid  and 8 bytes of data or less per frame. the solution is to use database definitions like dbc files. theres a really good writeup on what dbc files are and how they work here . dbc file entry for a frame and a signal, image from https:www.csselectronics.compagescandbcfiledatabaseintro i went ahead and picked josh wardells model3.dbc file, with additional records and collections from greg zimmermans github repo here, which had more uptodate signal definitions. after i had a dbc file to decode the data and a node publishing can bus data to a ros topic, the next task was decoding. i chose to go with a python node this time instead of c, as i was somewhat familiar with the cantools library. the process is: ros2qtcanbusqtcanbussender node sends messages to  fromcanbus topic in format: id: 599 data: 43, 88, 34, 4, 2, 64, 17, 1 2. ros2candecodecandecodenode decodes the message using dbc database. for message 599 from above, the dbc frame definition is: bo 599 id257dispeed: 8 vehiclebus sg dispeedchecksum : 081 1,0 0255  receiver sg dispeedcounter : 841 1,0 015  receiver sg diuispeed : 2491 1,0 0510  receiver sg diuispeedhighspeed : 3491 1,0 0510  receiver sg diuispeedunits : 3311 1,0 01  receiver sg divehiclespeed : 12121 0.08,40 40285 kph receiver val 599 diuispeedunits 1 dispeedkph 0 dispeedmph ; then, decoding the data translates to: dispeedchecksum: 221, dispeedcounter: 13, divehiclespeed: 46.96000000000001, diuispeed: 48, diuispeedunits: 1, diuispeedhighspeed: 0 3. if we enable the decodechoice option, numbers will be replaced with text values according to the dbc database.  replaces the number value in the message with the matching string value ...diuispeedunits: dispeedkph, ... 4. all frames will be published to diagnostics topic with the type diagnosticarray . one array will be one can frame with all signals as keyvalue . while i do not like the idea of storing values as strings, this seemed the most standard message type for the decoded messages. 5. in the case of gps coordinates or speedimu datasets, the package supports translating these messages to twist and navsatfix messages for sensor fusing, like for the localization of the car. default config file with parameters for my ros2candecode package after running the two nodes  ros2qtcanbus and ros2candecode , all the configured topics should be accessible with the respective decoded images. now, lets have a look at what weve collected. visualizing can bus data with foxglove dont get your hopes up too much just yet, there isnt much we can do with the data we have  the fancier sensors cameras, lidars are still down the line. still, seeing is believing, so lets look inside: speed, pedal position, and steering wheel angle with a neat map  all from our teslas can bus in foxglove studio . by using foxglove studio or with rviz2 we can see the freshly populated topics, including hundreds of sensors from different systems in our very own car. summary weve taken the first step to collect the necessary data to understand how autonomous vehicles work. with notsoexpensive cables and can loggers, you too can easily start your ros 2 and av journey, with foxglove providing a great tool to see where exactly you are in your physical journey. find the source code of the packages here: https:github.comtfoldiros2qtcanbus reach out to us here to learn more: lets talk  starschema we help your organization become datadriven. starschema.com read more stories from starschema: mqtt on steroids: running emqx enterprise on kubernetes learn how to deploy emqx, a robust mqtt message broker in your cloud or an onprem kubernetes cluster with a single medium.com avoid these 3 mistakes when working with a synapse dedicated sql pool learn three techniques for optimizing resource utilization and ensuring costeffectiveness with a synapse dedicated sql medium.com find the balance between cloud cost and efficiency learn how to measure the roi of a cloud migration and get clarity on the opportunities and challenges inherent in medium.com data engineering ros2 can bus foxglove tesla follow written by tamas foldi 303 followers  editor for hcltechstarschema blog helping enterprises to become more data driven  hcltech, cofounder  former ceo  starschema follow help status about careers press blog privacy terms text to speech teams