ros2  combine publisher, subscriber, service with practical robot examples (detect objects)  part 2 written by ruben alves  ros2 q&a | ros2 tutorials  19/01/2024 what we are going to learn learn how to combine a publisher, a subscriber, and a service in the same ros2 node to detect objects in a scene list of resources used in this post use this rosject: https://app.theconstructsim.com/l/5c13606c/ the construct: https://app.theconstructsim.com/ ros2 courses  ros2 basics in 5 days (python): https://app.theconstructsim.com/course/132 ros2 basics in 5 days (c++) : https://app.theconstructsim.com/course/133 apple detector: https://shrishailsgajbhar.github.io/post/opencv-apple-detection-counting banana detector: https://github.com/noorkhokhar99/open-cv-banana-detection overview ros2 (robot operating system version 2) is becoming the de facto standard framework for programming robots. in this post, we are going to learn how to combine publisher, subscriber, and service in ros2 to detect bananas and apples in an image. ros inside! ros inside before anything else, if you want to use the logo above on your own robot or computer, feel free to download it, print it, and attach it to your robot. it is really free. find it in the link below: ros inside logo opening the rosject in order to follow this tutorial, we need to have ros2 installed in our system, and ideally a ros2_ws (ros2 workspace). to make your life easier, we have already prepared a rosject for that: https://app.theconstructsim.com/l/5c13606c/ . just by copying the rosject (clicking the link above), you will have a setup already prepared for you. after the rosject has been successfully copied to your own area, you should see a run button. just click that button to launch the rosject (below you have a rosject example). combining publisher, subscriber & service in ros2 single node  run rosject (example of the run button) after pressing the run button, you should have the rosject loaded. now, lets head to the next section to get some real practice. modifying existing files in order to interact with ros2, we need a terminal. lets open a terminal by clicking the open a new terminal button. open a new terminal in this rosject we cloned the https://bitbucket.org/theconstructcore/fruit_detector and placed it inside the ~/ros2_ws/src folder. you can see its content with the following command in the terminal: ls ~/ros2_ws/src/fruit_detector/ the following output should be produced: custom_interfaces pub_sub_srv_ros2_pkg_example a new file called pubsubserv_example.py was created inside the fruit_detector/pub_sub_srv_ros2_pkg_example/scripts folder. you can see its content with the following command: cat ~/ros2_ws/src/fruit_detector/pub_sub_srv_ros2_pkg_example/scripts/pubsubserv_example.py you could have created that file also using the code editor. if you want to use the code editor, also known as ide (integrated development environment), you just have to open it as indicated in the image below: open the ide  code editor the following content was pasted to that file: #! /usr/bin/env python3 import rclpy from rclpy.node import node from sensor_msgs.msg import image from custom_interfaces.srv import stringservicemessage import os import cv2 from cv_bridge import cvbridge import ament_index_python.packages as ament_index class combinenode(node): def __init__(self, dummy=true): super().__init__('combine_node') self._dummy= dummy self.pkg_path = self.get_package_path("pub_sub_srv_ros2_pkg_example") self.scripts_path = os.path.join(self.pkg_path,"scripts") cascade_file_path = os.path.join(self.scripts_path,'haarbanana.xml') self.banana_cascade = cv2.cascadeclassifier(cascade_file_path) self.bridge = cvbridge() self.publisher = self.create_publisher(image, 'image_detected_fruit', 10) self.subscription = self.create_subscription( image, '/box_bot_1/box_bot_1_camera/image_raw', self.image_callback, 10) self.string_service = self.create_service( stringservicemessage, 'detect_fruit_service', self.string_service_callback) self.get_logger().info(f'ready combinenode') def get_package_path(self, package_name): try: package_share_directory = ament_index.get_package_share_directory(package_name) return package_share_directory except exception as e: print(f"error: {e}") return none def image_callback(self, msg): self.get_logger().info('received an image.') self.current_image = msg def string_service_callback(self, request, response): # handle the string service request self.get_logger().info(f'received string service request: {request.detect}') if request.detect == "apple": if self._dummy: # generate and publish an image related to apple detections apple_image = self.generate_apple_detection_image() self.publish_image(apple_image) else: self.detect_and_publish_apple() elif request.detect == "banana": if self._dummy: # generate and publish an image related to banana detections banana_image = self.generate_banana_detection_image() self.publish_image(banana_image) else: self.detect_and_publish_banana() else: # if no specific request unknown_image = self.generate_unknown_detection_image() self.publish_image(unknown_image) # respond with success and a message response.success = true response.message = f'received and processed: {request.detect}' return response def generate_unknown_detection_image(self): self.apple_img_path = os.path.join(self.scripts_path,'unknown.png') self.get_logger().warning("unknown path="+str(self.apple_img_path)) # replace this with your actual image processing logic # in this example, we create a simple red circle on a black image image = cv2.imread(self.apple_img_path) # replace with your image path if image is none: self.get_logger().error("failed to load the unknown image.") else: self.get_logger().warning("success to load the unknown image.") return self.bridge.cv2_to_imgmsg(image, encoding="bgr8") def generate_apple_detection_image(self): self.apple_img_path = os.path.join(self.scripts_path,'apple.png') self.get_logger().warning("apple path="+str(self.apple_img_path)) # replace this with your actual image processing logic # in this example, we create a simple red circle on a black image image = cv2.imread(self.apple_img_path) # replace with your image path if image is none: self.get_logger().error("failed to load the apple image.") else: self.get_logger().warning("success to load the apple image.") return self.bridge.cv2_to_imgmsg(image, encoding="bgr8") def generate_banana_detection_image(self): self.banana_img_path = os.path.join(self.scripts_path,'banana.png') self.get_logger().warning("banana path="+str(self.banana_img_path)) # replace this with your actual image processing logic # in this example, we create a simple yellow circle on a black image image = cv2.imread(self.banana_img_path) # replace with your image path if image is none: self.get_logger().error("failed to load the banana image.") else: self.get_logger().warning("success to load the banana image.") return self.bridge.cv2_to_imgmsg(image, encoding="bgr8") def publish_image(self, image_msg): if image_msg is not none: self.publisher.publish(image_msg) def detect_and_publish_apple(self): if self.current_image is not none: frame = self.bridge.imgmsg_to_cv2(self.current_image, desired_encoding="bgr8") # your apple detection code here (from approach_2.py) # high===== # (0.0, 238.935, 255.0) # low===== # (1.8, 255.0, 66.045) low_apple_raw = (0.0, 80.0, 80.0) high_apple_raw = (20.0, 255.0, 255.0) image_hsv = cv2.cvtcolor(frame, cv2.color_bgr2hsv) mask = cv2.inrange(image_hsv, low_apple_raw, high_apple_raw) cnts, _ = cv2.findcontours(mask.copy(), cv2.retr_external, cv2.chain_approx_simple) c_num = 0 radius = 10 for i, c in enumerate(cnts): ((x, y), r) = cv2.minenclosingcircle(c) if r > radius: print("ok="+str(r)) c_num += 1 cv2.circle(frame, (int(x), int(y)), int(r), (0, 255, 0), 2) cv2.puttext(frame, "#{}".format(c_num), (int(x) - 10, int(y)), cv2.font_hershey_simplex, 0.6, (255, 0, 0), 2) else: print(r) # publish the detected image as a ros 2 image message image_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8") self.publish_image(image_msg) else: self.get_logger().error("image not found") def detect_and_publish_banana(self): self.get_logger().warning("detect_and_publish_banana start") if self.current_image is not none: self.get_logger().warning("image found") frame = self.bridge.imgmsg_to_cv2(self.current_image, desired_encoding="bgr8") gray = cv2.cvtcolor(frame, cv2.color_bgr2gray) bananas = self.banana_cascade.detectmultiscale( gray, scalefactor=1.1, minneighbors=5, minsize=(30, 30), flags=cv2.cascade_scale_image) for (x, y, w, h) in bananas: cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3) cv2.puttext(frame, 'banana', (x-10, y-10), cv2.font_hershey_simplex, 1, (0, 255, 0)) # publish the detected image as a ros 2 image message self.get_logger().warning("bananadetection image publishing...") image_msg = self.bridge.cv2_to_imgmsg(frame, encoding="bgr8") self.publish_image(image_msg) self.get_logger().warning("bananadetection image publishing...done") else: self.get_logger().error("image not found") def main(args=none): rclpy.init(args=args) node = combinenode(dummy=false) rclpy.spin(node) node.destroy_node() rclpy.shutdown() if __name__ == '__main__': main() after creating that python file, we also modified the cmakelists.txt file of the pub_sub_srv_ros2_pkg_example package: ~/ros2_ws/src/fruit_detector/pub_sub_srv_ros2_pkg_example/cmakelists.txt we basically added  scripts/pubsubserv_example.py  to the list of files to be installed when we build our ros2 workspace. in the end, the content of ~/ros2_ws/src/fruit_detector/pub_sub_srv_ros2_pkg_example/cmakelists.txt is like this: cmake_minimum_required(version 3.8) project(pub_sub_srv_ros2_pkg_example) if(cmake_compiler_is_gnucxx or cmake_cxx_compiler_id matches "clang") add_compile_options(-wall -wextra -wpedantic) endif() find_package(ament_cmake required) find_package(sensor_msgs required) find_package(std_srvs required) find_package(custom_interfaces required) if(build_testing) find_package(ament_lint_auto required) set(ament_cmake__found true) set(ament_cmake_cpplint_found true) ament_lint_auto_find_test_dependencies() endif() # we add it to be able to use other modules of the scripts folder install(directory scripts rviz destination share/{project_name} ) install(programs scripts/example1_dummy.py scripts/example1.py scripts/example1_main.py scripts/pubsubserv_example.py destination lib/{project_name} ) ament_package() we then compiled specifically the pub_sub_srv_ros2_pkg_example package using the following command: cd ~/ros2_ws/ source install/setup.bash colcon build --packages-select pub_sub_srv_ros2_pkg_example after the package is compiled, we could run that python script using the following command: cd ~/ros2_ws source install/setup.bash ros2 run pub_sub_srv_ros2_pkg_example pubsubserv_example.py after running that script you are not going to see any output because we are not printing anything. but, lets try to list the services in a second terminal by typing ros2 node list . if everything goes well, we should be able to see the combine_node node:  ros2 node list /combine_node launching the simulation so far we cant see what our node is capable of. lets launch a simulation so that we can understand our node better. for that, lets run the following command in a third terminal : ros2 launch box_bot_gazebo garden_main.launch.xml a simulation similar to the following should appear in a few seconds: combine publisher, subscriber & service in ros2 single node  simulation after launching the simulation, in the first terminal where we launched our node, we should start seeing messages like the following: ... [info] [1699306370.709477898] [combine_node]: received an image. [info] [1699306373.374917545] [combine_node]: received an image. [info] [1699306376.390623360] [combine_node]: received an image. [info] [1699306379.277906884] [combine_node]: received an image ... we will soon understand what these messages mean. see what the robot sees through rviz2 now that the simulation is running, we can open rviz2 (ros visualization version 2). to make it easier for you to see the robot model, and the robot camera, a fruit.rviz file was created at ~/ros2_ws/src/fruit_detector/pub_sub_srv_ros2_pkg_example/rviz/fruit.rviz . you can tell rviz2 to load that config file using the following command: rviz2 --display-config ~/ros2_ws/src/fruit_detector/pub_sub_srv_ros2_pkg_example/rviz/fruit.rviz a new screen should pop up in a few seconds, and you should be able to see what the robot camera sees, as well as the robot model. the ros2 topic that we set for the camera was /box_bot_1/box_bot_1_camera/image_raw . you can find this topic if you list the topics in another terminal using ros2 topic list . if you look at the topic that we subscribe to at the __init__ method of the combinenode class, it is exactly this topic: self.subscription = self.create_subscription( image, '/box_bot_1/box_bot_1_camera/image_raw', self.image_callback, 10) when a new image message comes, the image_callback method is called. it essentially saves the image in an internal variable called current_image : def image_callback(self, msg): self.get_logger().info('received an image.') self.current_image = msg at the __init__ method we also created a service for analyzing an image and detecting whether or not it contains a banana: def __init__(self, dummy=true): super().__init__('combine_node') # ... self.string_service = self.create_service( stringservicemessage, 'detect_fruit_service', self.string_service_callback) def string_service_callback(self, request, response): # handle the string service request self.get_logger().info(f'received string service request: {request.detect}') if request.detect == "apple": if self._dummy: # generate and publish an image related to apple detections apple_image = self.generate_apple_detection_image() self.publish_image(apple_image) else: self.detect_and_publish_apple() elif request.detect == "banana": if self._dummy: # generate and publish an image related to banana detections banana_image = self.generate_banana_detection_image() self.publish_image(banana_image) else: self.detect_and_publish_banana() else: # if no specific request unknown_image = self.generate_unknown_detection_image() self.publish_image(unknown_image) # respond with success and a message response.success = true response.message = f'received and processed: {request.detect}' return response by analyzing the code above, we see that when the detect_fruit_service service that we created is called, it calls the string_service_callback method that is responsible for detecting bananas and apples . now, going back to the messages we see in the first terminal: ... [info] [1699306370.709477898] [combine_node]: received an image. [info] [1699306373.374917545] [combine_node]: received an image. [info] [1699306376.390623360] [combine_node]: received an image. [info] [1699306379.277906884] [combine_node]: received an image ... these messages basically say that we are correctly receiving the image messages from the /box_bot_1/box_bot_1_camera/image_raw topic mentioned earlier. if we list the services, we should find a service named . lets try it, by running the following command in a free terminal: ros2 service list you should see a huge number of services, and among them, you should be able to find the following one, that we created: /detect_fruit_service by the way, the reason why we have so many services is that the gazebo simulator generates a lot of services, making it easier to interact with gazebo using ros2. now, lets call that service. in order to detect an apple, a banana, and a strawberry, we could run the following commands respectively: ros2 service call /detect_fruit_service custom_interfaces/srv/stringservicemessage "detect: 'apple'" ros2 service call /detect_fruit_service custom_interfaces/srv/stringservicemessage "detect: 'banana'" ros2 service call /detect_fruit_service custom_interfaces/srv/stringservicemessage "detect: 'strawberry'" if you dont understand the commands we have been using so far, i highly recommend you take the ros2 basics course: https://app.theconstructsim.com/courses/132 . alright. after calling the service to detect a banana , we should have an output similar to the following: requester: making request: custom_interfaces.srv.stringservicemessage_request(detect='banana') response: custom_interfaces.srv.stringservicemessage_response(success=true, message='received and processed: banana') indicating that the service correctly detected a banana. if you check the logs in the first terminal where we launched our node, you will also see a message similar to the following: bananadetection image publishing... if you check the window where rviz (robot visualizer), when detecting the apple you should have a green circle around the apple, just like in the image below: ros2  combine publisher, subscriber, and service with practical robot examples  part 2 congratulations. now you know how to combine different ros2 pieces in a single node. we hope this post was really helpful to you. if you want a live version of this post with more details , please check the video in the next section. youtube video so this is the post for today. remember that we have the live version of this post on youtube. if you liked the content, please consider subscribing to our youtube channel. we are publishing new content ~every day. keep pushing your ros learning. related courses & training if you want to learn more  ros and ros2, we recommend the following courses: ros2 basics in 5 days humble (python): https://app.theconstructsim.com/course/132 ros2 basics in 5 days humble (c++) : https://app.theconstructsim.com/course/133 open-rmf / fleet management training : https://www.theconstruct.ai/robot-fleet-management-ros2-open-rmf-training/ get ros2 industrial ready- hands-on training by the construct cover.png topics: check out these related posts how to become a robotics developer may 26, 2018 updated: july 26, 2023 robotics needs developers! robotics needs software engineers and software... read more 130. the open source robotics alliance apr 8, 2024 i would like to dedicate this episode to all the ros developers out there who are thinking and... read more 129. ros2ai jan 29, 2024 i would like to dedicate this episode to all the ros developers who believe that chatgpt or... read more  older entries 0 comments pin it on pinterest share this twitter linkedin reddit facebook gmail