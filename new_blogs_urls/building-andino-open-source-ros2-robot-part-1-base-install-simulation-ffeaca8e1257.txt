open in app sign up sign in write sign up sign in building andino  open source ros2 robot  part 1 base install  simulation robofoundry  follow 10 min read  feb 19, 2024  listen share last year i came across a rosnews article that showed andino robot and i thought it would be a perfect robot to build later as i seem to have all the parts or at least i can cannibalize from my older robots. well the time to build andino arrived in jan 2024 and i have been hard at work since last few weeks to build this new robot and document steps along the way. spoiler alert, its a really neat little robot and i have enjoyed working on building it. as you would expect, here is my blog entry for this build. the basic hardware and software setup is all documented on the andino github repository . however, while going through the build i realized that either i had to change a few things based on the parts i have or in some cases there is not enough detail in the instructions provided on the github repo. my observation was that software part of instructions they have done an awesome job but the hardware part of the build is pretty minimal and requires one to either try things out or take best guess. i will try to point out where things may be different or add more details that others may find more useful so its easier. interesting thing about this particular robot is that it does not use imu so you dont have to fuse the odometry from encoders and imu to get to final one which simplifies things a bit. andino is gazebo simulation thoughts on bill of materials and adjustmentsalternatives the bill of materials is very well documented. imo, all the parts together should not cost more than 250300, rpi and lidar being the biggest portion of that budget. this is a bit more expensive than the esp32 robot build i had described in the past as that one eliminates the need for rpi using microros but still very affordable. youll be able to see that the basic components are as follows: raspberry pi  i used rpi4 with 4 gb ram same as recommended arduino uno  i used an existing uno i had and it worked fine same as recommended l298n  i also had a bunch of l298ns lying around as these are very cheap to get and very versatile same as recommended dc motors  for this i already had two of the lshaped dfrobot fit0458 not same as recommended that i had purchased a while ago and waiting to be used in a project. the main reason for using proper dc motor with encoder integrated is that i dont have to fuddle around with the unreliable encoders. i have tried to use those cheap optical encoder disks mounted on motor shaft but that thing never worked right for me, thats just my experience. these motors are not that expensive, you can get even cheaper versions of these on digikey or aliexpress that not lshaped and easy to mount. lidar  i used same lidar as they recommend an rplidar same as recommended camera  i used rpi camera v2 that i already had same as recommended. you can probably use v3 as well. there was quite a bit of pain to get this to work with ubuntu server as ill describe later but it works fine at the end. power bankbattery  they recommend just single 5v power bank for power. but this is not very practical as this can result in rpi having power brown out if motors are pulling a lot more current and cannot supply enough power to rpi and arduino. so instead of doing this i used two battery packs  1. phonetablet power bank to power rpi  arduino as arduino gets power from usb port of rpi. 2. a separate 4aa battery holder to power the dc motors as dc motors im using require 37.5v for operating voltage. not same as recommended base plates and wheels  because i used different motors, i had to design and 3d print my own base plate and motor mounting plates, i can share the freecad models in my fork of the original andino repository. i basically printed two copies of same base plate and had the different components mounted on two tiers. this is another area that is not very well documented in the andino repo for assembling the hardware together. ill provide more details and photos along the way so it may help. for wheels i used the standard robot kit wheels that are typically supplied with ttmotor robot kits. also, for the wheel castor i had one that was from an old kit that i reused from another old robot project. ill provide the links to all the parts at the end so if you need to find those or equivalent it will be easier. not same as recommended for plates but same for wheels operating system  they recommend ubuntumate as operating system, but i have done some basic comparison and there is not a big difference in functional aspects of ubuntumate and ubuntu and since im very used to ubuntu i stayed with ubuntu server without gui. rpi imager allows you to create an ubuntu server 22.04 jammy 64bit version sd card from their rpi imager app directly that you can install on ubuntu or any other os laptopcomputer you have to make the sd card. i went with a 64 gb sd card. not same as recommended. you can find additional instructions for installing some more tools after ubuntu server is up and running on the andino repo. another advantage of going with rpi imager is that it allows you to enter wifi settings, customize ubuntu username and password and computer name in the settings area of the app so when you plug the sd card into your rpi it will connect to your wifi network right away and you can ssh into it and start working instead of trying to find mousekeyboardscreen to connect to rpi and then manually configure all those things, its just a waste of time to do it that way unless you insist on having a gui to rpi. preparing the operating system and software after you have got your basic ubuntu server up and running on rpi and you are able to login, there are some more steps you are going to have to perform. main things include installing ros2 humble and dev tools installing dependencies for arduino, camera, rplidar setting up correct names and permissions for usb ports for hardware devices like arduino, rplidar etc building andino ros2 workspace so we can run andino in simulation mode. setting up joystick optional if you are going to use gamepad installing ros2 on both laptop and rpi before doing anything else on your brand new ubuntu server installation do the following steps: sudo apt udpate  sudo apt upgrade sudo apt install git nettools softwarepropertiescommon buildessential y this is the easiest step, i always recommend everyone to follow linorobotros2me repository as it makes it dumb simple to install ros2 humble with exactly right packages for either laptop or rpi, it will detect the hardware architecture and install desktopgui packages on laptop but on rpi it will install base setup. its pretty slick. here are the commands you need to execute to install it on both your laptopcomputer and rpirobot computer. git clone https:github.comlinorobotros2me.git .install installing dependencies for arduino, camera and rplidar only perform this on rpi for arduino follow the steps here  https:github.comekumenosandinotreehumbleandinohardwarearduino for camera follow the steps here  https:github.comekumenosandinotreehumbleandinohardwarearduino for rplidar follow the steps here  https:github.comekumenosandinotreehumbleandinohardwarearduino setting up correct names and permissions for usb ports only perform this on rpi make sure to follow all the steps described in usb port name configuration section here  https:github.comekumenosandinotreehumbleandinohardwareusbportnameconfiguration usb port name configuration is extremely important because andino ros2 workspace code looks for these exact names for the usb ports in various launch file and urdf files and if you dont follow that youll have to search and find where all those things are located and modify them. please dont do that it will be a lot easier if you just fix the usb port names first. i learned it the hard way. at the end you should be able to confirm everything looks good by running this command: ls l devttyusb  you should see something like this in output notice the last two items crwrw 1 root dialout 188, 0 sep 2 15:09 devttyusb0 crwrw 1 root dialout 188, 1 sep 2 15:09 devttyusb1 lrwxrwxrwx 1 root root 7 sep 2 15:09 devttyusbarduino  ttyusb0 lrwxrwxrwx 1 root root 7 sep 2 15:09 devttyusblidar  ttyusb1 building andino ros2 workspace on both laptop and rpi follow steps to build the andino workspace on both laptop and rpi as described here  https:github.comekumenosandinotreehumbleandinohardwarecreaterobotworkspace tip while running rosdep command see this note  note that option r has been added. for arm based processors, there are missing packages, e.g. those related to simulation. we would not try to run the simulation in the compute platform of andino, however for convenience it is added here. what this means and how rosdep functions, if you dont supply r switch, the rosdep will stop at very first step where it encounters error installing packages e.g. there is no gazebo package for ubuntu 22.04 server for aarm64 architecture for rpi and youll be stuck there. the r option tells rosdep to continue despite the errors so even though youll see those errors generated for the three simulation folders  andinogzclassic, andinonavigation, andinoslam, it will still install all the necessary ros dependencies for the robot to work. youll not face these errors when you run the same rosdep command on your laptop as the gazebo and other packages would already exist there or it will be able to install if not. you can also follow steps listed in extra recommendations  tools section that will make the process of troubleshooting and getting robot up smoother  https:github.comekumenosandinotreehumbleandinohardwareextrarecommendationstools i would highly recommend that you setup the rosdomainid environment variable correctly on both laptop and rpi. at this point we are ready to build the andino workspace and run simulation on laptophost computer not on rpirobot computer yet. follow the steps here to git clone code to your host machine and build the workspace  https:github.comekumenosandino?tabreadmeovfilecolconworkspace follow these steps to build and launch simulation to test everything works well in simulation mode. note: if you are going to use gamepad as controller follow the steps in section below named setting up joystick before launching the simulation in terminal windows.  on host computer  after building the workspace as described above  launch three different launch files in three separate terminal windows  terminal window  1  make sure to source your workspace source installsetup.bash ros2 launch andinogzclassic andinoonerobot.launch.py usegazeboroscontrol:true  terminal window  2  make sure to source your workspace source installsetup.bash ros2 launch andinobringup andinorobot.launch.py  terminal window  3  make sure to source your workspace source installsetup.bash ros2 launch andinobringup teleopjoystick.launch.py  at this point, while joystick is connected to laptop,  hold down the lbrb and move the joysticks,  the robot should move in both gazebo classic and rviz2 the first terminal will launch the rviz simulator and gazebo classic, the second window will launch all the necessary nodes to publish robot description and interact with gazebo plugins and third one will launch the joystick teleop node that will listen for your joystick controller. youll be able to see the robot in both rviz and gazebo classic and control the movements of the robot in the simulators. it should look something like this: setting up joystick the last step of setting up joystick is optional, i would recommend that you follow the steps to setup the joystick using this blog article from articulated robotics using the gamepad section and initially plug in the usb key for your gamepad controller if you are going to use that for robot control in your laptop and test it out to make yourself familiar with which keys are the ones that are expected to be pressed for robot movement. once you are familiar with that, you can unplug the usb key from laptop and plug it into your rpi. it will work just fine even if you left it in laptop, it is not required to have it plugged into rpi. thats the beauty of ros2 framework that all the ros joystick messages are available to all subscribers on same network and rosdomainid. thats it, if you followed along this far, you should have andino robot working in simulation mode. and you should already have a solid base within your rpi for working on getting the real robot working in next article where we will dive deep into hardware assembly and getting robot to move while it is propped up on the stand where we can move the wheels, do some basic tests to make sure we are able to control the wheels via joystick on real robot. have fun building, this is a really fun robot project that can be affordable to everyone and i appreciate all the efforts of open source community contributors to andino repository and and ekumen team. this will have a real impact on all the selflearners out there who do not have huge budgets to purchase expensive equipment but they can still learn the same concepts with a much affordable setup on their own. references  andino  an opensource lowcost educational robot hi there ros community! let me introduce you to andino!  what is andino? andino is a full opensource differential discourse.ros.org github  ekumenosandino: opensource diff drive robot ros 2 compatible opensource diff drive robot ros 2 compatible. contribute to ekumenosandino development by creating an account on github.com github  linorobotros2me: ros2 installation file ros2 installation file. contribute to linorobotros2me development by creating an account on github. github.com making a mobile robot 14a  teleoperation what is teleop? articulatedrobotics.xyz raspberry pi os  raspberry pi from industries large and small, to the kitchen table tinkerer, to the classroom coder, we make computing accessible www.raspberrypi.com how to install ubuntu server on your raspberry pi  ubuntu ubuntu is an open source software operating system that runs from the desktop, to the cloud, to all your internet ubuntu.com ros2 robotics raspberry pi arduino follow written by robofoundry 331 followers follow help status about careers press blog privacy terms text to speech teams